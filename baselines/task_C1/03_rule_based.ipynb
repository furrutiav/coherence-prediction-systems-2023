{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87916e1",
   "metadata": {},
   "source": [
    "## Libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61182d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f16b5",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9ece36",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train = pd.read_excel(\"../../data/train_task_C1.xlsx\", index_col=\"id\")\n",
    "A_val = pd.read_excel(\"../../data/val_task_C1.xlsx\", index_col=\"id\")\n",
    "A_test = pd.read_excel(\"../../data/test_task_C1.xlsx\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec0a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = A_train[\"Q A\".split()]\n",
    "y_train = A_train[\"label\"]\n",
    "\n",
    "X_test = A_test[\"Q A\".split()]\n",
    "y_test = A_test[\"label\"]\n",
    "\n",
    "X_val = A_val[\"Q A\".split()]\n",
    "y_val = A_val[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0dfe1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('En 5 días, las gallinas de una granja pusieron 700 huevos.   ¿Es posible con esta información crear un gráfico de barras o pictograma? Argumenta tu respuesta.',\n",
       " 'mn\\n',\n",
       " 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 280\n",
    "q = X_train[\"Q\"][A_train[\"label_C1\"] == 1].iloc[ix]\n",
    "a = X_train[\"A\"][A_train[\"label_C1\"] == 1].iloc[ix]\n",
    "y = y_train[A_train[\"label_C1\"] == 1].iloc[ix]\n",
    "q, a, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24addcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_rules(q, a):\n",
    "    if any([x in a.lower() for x in [\"caca\", \":D\", \":c\", \":)\", \":(\", \n",
    "                                     \"nose\", \"profe\", \"tia\", \"noce\", \":v\"]]):\n",
    "        return 1\n",
    "    else:\n",
    "        if any([x in q.lower() for x in [\"¿cuánta\", \"¿cuánto\",\"¿cuanta\", \"¿cuanto\", \"¿con cuánta\", \n",
    "                                         \"¿con cuanta\", \"¿con cuánto\", \"¿con cuanto\", \"¿a cuántos\", \n",
    "                                         \"¿a cuántas\", \"¿qué cantidad\"]]):\n",
    "            if any([x in q.lower() for x in [\"explica\", \"explique\", \"justifique\", \n",
    "                                             \"con tus palabras\", \"con sus palabras\", \"en palabras\", \n",
    "                                             \"plantea la\", \"escribe\", \"¿qué\"]]):\n",
    "                #Q=2\n",
    "                nums = len(re.findall(r'[0-9]+', a))\n",
    "                no_nums = len(\"\".join(a.split()))-nums\n",
    "                if no_nums>0 and nums>0:\n",
    "                    return 0\n",
    "            else:\n",
    "                #Q=1\n",
    "                nums = len(re.findall(r'[0-9]+', a))\n",
    "                if nums>0:\n",
    "                    return 0\n",
    "        elif any([x in q.lower() for x in [\"¿está correcto\", \"¿esta correcto\", \"¿está correcta\", \n",
    "                                         \"¿esta correcta\", \"¿es correcta\", \"¿es correcto\", \n",
    "                                         \"correcto?\", \"correcta?\", \"equivocado?\", \"equivocada?\",\n",
    "                                         \"¿estará correcto\", \"¿estara correcto\", \"¿estara correcta\",\n",
    "                                         \"¿estará correcta\", \"afirmación?\", \"afirmacion?\"]]):\n",
    "            #Q=3\n",
    "            aff = len([x for x in [\"si\", \"no\", \"correcto\", \"mal\", \"bien\", \"por que\", \"rason\", \"porque\", \"razon \"] if x in a.lower()])\n",
    "            if aff>0:\n",
    "                return 0\n",
    "        else:\n",
    "            nums = len(re.findall(r'[0-9]+', a))\n",
    "            no_nums = len(\"\".join(a.split()))-nums\n",
    "            num_vow = len([x for x in a if x in \"aeiou\"])\n",
    "            if no_nums>0:\n",
    "                if 0.2<num_vow/no_nums<0.8:\n",
    "                    return 0\n",
    "    return 1\n",
    "\n",
    "def clf_rules_predict(df):\n",
    "    o = []\n",
    "    for ix in df.index:\n",
    "        row = df.loc[ix]\n",
    "        q, a = row[\"Q\"], row[\"A\"]\n",
    "        q = str(q)\n",
    "        a = str(a)\n",
    "        oi = clf_rules(q, a)\n",
    "        o.append(oi)\n",
    "    return np.array(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa48bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac27975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.65 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.927099</td>\n",
       "      <td>0.480702</td>\n",
       "      <td>0.861061</td>\n",
       "      <td>0.703900</td>\n",
       "      <td>0.867626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.911368</td>\n",
       "      <td>0.533766</td>\n",
       "      <td>0.861061</td>\n",
       "      <td>0.722567</td>\n",
       "      <td>0.861061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.919166</td>\n",
       "      <td>0.505846</td>\n",
       "      <td>0.861061</td>\n",
       "      <td>0.712506</td>\n",
       "      <td>0.864100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>10019.000000</td>\n",
       "      <td>1540.000000</td>\n",
       "      <td>0.861061</td>\n",
       "      <td>11559.000000</td>\n",
       "      <td>11559.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1  accuracy     macro avg  weighted avg\n",
       "precision      0.927099     0.480702  0.861061      0.703900      0.867626\n",
       "recall         0.911368     0.533766  0.861061      0.722567      0.861061\n",
       "f1-score       0.919166     0.505846  0.861061      0.712506      0.864100\n",
       "support    10019.000000  1540.000000  0.861061  11559.000000  11559.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_rules_predict(X_train)\n",
    "report = classification_report(y_train, y_pred, output_dict=True)\n",
    "train_report = pd.DataFrame(report)\n",
    "train_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb768a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.932114</td>\n",
       "      <td>0.504566</td>\n",
       "      <td>0.867495</td>\n",
       "      <td>0.718340</td>\n",
       "      <td>0.874871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.913546</td>\n",
       "      <td>0.569588</td>\n",
       "      <td>0.867495</td>\n",
       "      <td>0.741567</td>\n",
       "      <td>0.867495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.922736</td>\n",
       "      <td>0.535109</td>\n",
       "      <td>0.867495</td>\n",
       "      <td>0.728923</td>\n",
       "      <td>0.870839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2510.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>0.867495</td>\n",
       "      <td>2898.000000</td>\n",
       "      <td>2898.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.932114    0.504566  0.867495     0.718340      0.874871\n",
       "recall        0.913546    0.569588  0.867495     0.741567      0.867495\n",
       "f1-score      0.922736    0.535109  0.867495     0.728923      0.870839\n",
       "support    2510.000000  388.000000  0.867495  2898.000000   2898.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_rules_predict(X_val)\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "val_report = pd.DataFrame(report)\n",
    "val_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e92a6639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.881239</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.855244</td>\n",
       "      <td>0.789578</td>\n",
       "      <td>0.844412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.946396</td>\n",
       "      <td>0.492647</td>\n",
       "      <td>0.855244</td>\n",
       "      <td>0.719521</td>\n",
       "      <td>0.855244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.912656</td>\n",
       "      <td>0.577586</td>\n",
       "      <td>0.855244</td>\n",
       "      <td>0.745121</td>\n",
       "      <td>0.845345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>541.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.855244</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.881239    0.697917  0.855244    0.789578      0.844412\n",
       "recall       0.946396    0.492647  0.855244    0.719521      0.855244\n",
       "f1-score     0.912656    0.577586  0.855244    0.745121      0.845345\n",
       "support    541.000000  136.000000  0.855244  677.000000    677.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_rules_predict(X_test)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "test_report = pd.DataFrame(report)\n",
    "test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10019\n",
       "1     1540\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d75f93",
   "metadata": {},
   "source": [
    "## Save pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b4eae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(clf, open(\"results/clf_rule_based_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cff99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(best_params, open(\"results/best_params_rule_based_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b450ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_report, open(\"results/train_report_rule_based.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0869748",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(val_report, open(\"results/val_report_rule_based.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b34afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_report, open(\"results/test_report_rule_based.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
