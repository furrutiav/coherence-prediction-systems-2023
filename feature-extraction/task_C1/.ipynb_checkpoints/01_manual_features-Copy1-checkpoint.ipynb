{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77fb92c",
   "metadata": {},
   "source": [
    "## Libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f823625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce51f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U spacy\n",
    "import spacy\n",
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecaa68e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\felip\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a960c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d783de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Levenshtein in c:\\users\\felip\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\felip\\anaconda3\\lib\\site-packages (from Levenshtein) (61.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Levenshtein\n",
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf9456",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89409385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_id</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163111</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>calcular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163112</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163113</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>no porque laura dividio 16 pero no dijo restar2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163114</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>NO CORRECTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163115</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343006</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>àngulo recto mide 90,àngulo agudo mide menos d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343007</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>AGUDO MENOD DE 90       -LLANO MIDE 180       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343008</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>agudo menos de 90° obtuso menos de 90° recto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343009</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>agudo  menos de 90°  obtuso mas de 90° recto 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343039</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>ángulo recto mide 90 g ángulo obtuso mide 185 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111316 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Q_id                                                  Q  \\\n",
       "id                                                                 \n",
       "163111  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "163112  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "163113  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "163114  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "163115  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "...       ...                                                ...   \n",
       "343006  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "343007  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "343008  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "343009  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "343039  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "\n",
       "                                                        A  \n",
       "id                                                         \n",
       "163111                                           calcular  \n",
       "163112                                                 no  \n",
       "163113    no porque laura dividio 16 pero no dijo restar2  \n",
       "163114                                        NO CORRECTO  \n",
       "163115                                                 NO  \n",
       "...                                                   ...  \n",
       "343006  àngulo recto mide 90,àngulo agudo mide menos d...  \n",
       "343007  AGUDO MENOD DE 90       -LLANO MIDE 180       ...  \n",
       "343008       agudo menos de 90° obtuso menos de 90° recto  \n",
       "343009  agudo  menos de 90°  obtuso mas de 90° recto 9...  \n",
       "343039  ángulo recto mide 90 g ángulo obtuso mide 185 ...  \n",
       "\n",
       "[111316 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_C1 = pd.read_excel(\"D:\\\\github\\\\coherence-prediction\\\\data/2022_task_C1.xlsx\", index_col=0)\n",
    "task_C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_id</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163111</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>calcular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163112</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163113</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>no porque laura dividio 16 pero no dijo restar2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163114</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>NO CORRECTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163115</th>\n",
       "      <td>14662</td>\n",
       "      <td>Laura tiene una hoja cuadrada que ha dividido ...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343006</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>àngulo recto mide 90,àngulo agudo mide menos d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343007</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>AGUDO MENOD DE 90       -LLANO MIDE 180       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343008</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>agudo menos de 90° obtuso menos de 90° recto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343009</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>agudo  menos de 90°  obtuso mas de 90° recto 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343039</th>\n",
       "      <td>34957</td>\n",
       "      <td>Nombra todos los tipos de ángulos según su med...</td>\n",
       "      <td>ángulo recto mide 90 g ángulo obtuso mide 185 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111316 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Q_id                                                  Q  \\\n",
       "id                                                                 \n",
       "163111  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "163112  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "163113  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "163114  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "163115  14662  Laura tiene una hoja cuadrada que ha dividido ...   \n",
       "...       ...                                                ...   \n",
       "343006  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "343007  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "343008  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "343009  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "343039  34957  Nombra todos los tipos de ángulos según su med...   \n",
       "\n",
       "                                                        A  \n",
       "id                                                         \n",
       "163111                                           calcular  \n",
       "163112                                                 no  \n",
       "163113    no porque laura dividio 16 pero no dijo restar2  \n",
       "163114                                        NO CORRECTO  \n",
       "163115                                                 NO  \n",
       "...                                                   ...  \n",
       "343006  àngulo recto mide 90,àngulo agudo mide menos d...  \n",
       "343007  AGUDO MENOD DE 90       -LLANO MIDE 180       ...  \n",
       "343008       agudo menos de 90° obtuso menos de 90° recto  \n",
       "343009  agudo  menos de 90°  obtuso mas de 90° recto 9...  \n",
       "343039  ángulo recto mide 90 g ángulo obtuso mide 185 ...  \n",
       "\n",
       "[111316 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_C1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c26bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd030d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_md')\n",
    "spanish_stopwords = stopwords.words(\"spanish\")\n",
    "class_numbercheckspeller = imp.load_source('module.name', '../lib/class_numbercheckspeller.py')\n",
    "base_symspell = pickle.load(open(\"../lib/base_symspell.pickle\", \"rb\"))\n",
    "D_correction = pickle.load(open(\"../lib/D_correction.pickle\", \"rb\"))\n",
    "ws = class_numbercheckspeller.SymSpellNumbers(base_symspell, D_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef435e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rae_ud = pickle.load(open(\"../lib/resource_rae_ud.pickle\", \"rb\"))\n",
    "special_words = pickle.load(open(\"../lib/special_words.pickle\", \"rb\"))\n",
    "keywords_C1 = special_words[\"keywords_C1\"]\n",
    "slang_C1 = special_words[\"slang_C1\"]\n",
    "bad_words = special_words[\"bad_words\"]\n",
    "recurrent_words = special_words[\"recurrent_words\"]\n",
    "generated_faces = pickle.load(open(\"../lib/faces.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7f92d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump({\n",
    "#     \"keywords_C1\": keywords_C1, \n",
    "#     \"slang_C1\": slang_C1, \n",
    "#     \"bad_words\": bad_words, \n",
    "#     \"recurrent_words\": recurrent_words\n",
    "# }, open(\"../lib/special_words.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbd70180",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = punctuation+\"´\"+\"¡\"\n",
    "vowel = \"aeiou\"\n",
    "digit = \"0123456789\"\n",
    "blank = \" \"\n",
    "math_punct = \"\"\"$%()*+,-./:<=>[\\]{}x\"\"\"\n",
    "list_rae = dic_rae_ud[\"rae\"]\n",
    "list_ud = dic_rae_ud[\"ud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a25e6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_faces = []\n",
    "for f in generated_faces:\n",
    "    if all(c in punct for c in f):\n",
    "        punct_faces.append(f)\n",
    "        \n",
    "no_digit_faces = []\n",
    "for f in generated_faces:\n",
    "    if not f.isdigit():\n",
    "        no_digit_faces.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88261775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_multiple(string, list_replace, replace_ch):\n",
    "    for ch in list_replace:\n",
    "        if ch in string:\n",
    "            string = string.replace(ch, replace_ch)\n",
    "    return string\n",
    "\n",
    "def get_relevants_subjects(q):\n",
    "    oo = {\"PROPN\": [], \"NOUN\": []}\n",
    "    bi_oo = {\"NOUN-ADP\": [], \"NOUN-PROPN\": []}\n",
    "    nlp_q = []\n",
    "    for t in nlp(q):\n",
    "        r = t.text, t.tag_, t.dep_, t.is_alpha, t.is_stop\n",
    "        nlp_q.append(r)\n",
    "    for r in nlp_q:\n",
    "        if r[1] == \"PROPN\":\n",
    "            oo[\"PROPN\"].append(r)\n",
    "        elif r[1] == \"NOUN\":\n",
    "            oo[\"NOUN\"].append(r)\n",
    "    for k in range(len(nlp_q)-1):\n",
    "        r1, r2 = nlp_q[k], nlp_q[k+1]\n",
    "        if r1[1] == \"NOUN\" and r2[1] == \"ADP\":\n",
    "            bi_oo[\"NOUN-ADP\"].append((r1, r2))\n",
    "        elif r1[1] == \"NOUN\" and r2[1] == \"PROPN\":\n",
    "            bi_oo[\"NOUN-PROPN\"].append((r1, r2))\n",
    "    relevants = []\n",
    "    for x in oo[\"PROPN\"]:\n",
    "        if x[3]:\n",
    "            relevants.append(x)\n",
    "    for x in oo[\"NOUN\"]:\n",
    "        if x[2] in [\"nsubj\"]:\n",
    "            relevants.append(x)\n",
    "    for x, y in bi_oo[\"NOUN-PROPN\"]:\n",
    "        relevants.append(x)\n",
    "        relevants.append(y)\n",
    "    for x, y in bi_oo[\"NOUN-ADP\"]:\n",
    "        if x[2] not in [\"nmod\", \"obj\", \"obl\"]:\n",
    "            relevants.append(x)\n",
    "        if y[2] not in [\"case\"] and not y[4]:\n",
    "            relevants.append(y)\n",
    "    return list(set([x[0].lower() for x in relevants]))\n",
    "\n",
    "def get_attrib(a):\n",
    "    a = \"\" if a == \"nan\" else a\n",
    "    rel_subj = get_relevants_subjects(a)\n",
    "    a_org_tokens = a.split()\n",
    "    a_lower_org_tokens = a.lower().split()\n",
    "    a_lower_org_tokens_wo_punct = replace_multiple(\" \".join(a_lower_org_tokens), punct, \" \").split()\n",
    "    a_ud = [x for x in a_org_tokens if (x.lower() in list_ud) and not (x.lower() in list_rae)]\n",
    "    a = unidecode(a)\n",
    "    a = a.replace(\"\\n\", \" \")\n",
    "    a = \" \".join(a.lower().split())\n",
    "    a = ws.apply(a)\n",
    "    a = \" \".join([x.strip() for x in re.split(r'(-?\\d*\\.?\\d+)', a)])\n",
    "    lf_a = [(t.text, t.lemma_, t.tag_) for t in nlp(\" \".join(a_org_tokens))]\n",
    "    for propn_ in [\"matemáticas\", \"matemáticas\", \"matemática\", \"matematica\", \"matematicas\",\n",
    "                   \"sofia\", \"renata\", \"camila\", \"pia\",\"pía\", \"carla\", \"pamela\", \"patricia\", \n",
    "                   \"matilde\", \"nama\", \"mamá\", \"amigo\", \"amiga\", \"amigos\", \"amigas\"]:\n",
    "        if propn_ in a_lower_org_tokens+a_org_tokens+a.split():\n",
    "            lf_a.append((propn_, propn_, \"PROPN\"))\n",
    "    aux_list = []\n",
    "    if any([x in \" \".join(a_lower_org_tokens) for x in [\"lo mismo\", \"la misma\", \n",
    "                                                        \"los dos\", \"las dos\", \n",
    "                                                        \"los 2\", \"las 2\"]]) or any([x in a for x in  [\"lo mismo\", \"la misma\", \"los dos\", \"las dos\", \"los 2\", \"las 2\"]]):\n",
    "        aux_list.append(\"ambos\")\n",
    "        \n",
    "    return {\n",
    "        \"clean\": a,\n",
    "        \"org_tokens\": a_org_tokens,\n",
    "        \"lower_org_tokens\": a_lower_org_tokens,\n",
    "        \"org_tokens_wo_punct\": a_lower_org_tokens_wo_punct, \n",
    "        \"tokens\": a.split(),\n",
    "        \"blank\": list(map(a.lower().count, blank))[0],\n",
    "        \"vowel\": list(map(a.lower().count, vowel)),\n",
    "        \"punct\": list(map(a.lower().count, punct)),\n",
    "        \"math_punct\": list(map(a.lower().count, math_punct)),\n",
    "        \"digit\": list(map(a.lower().count, digit)),\n",
    "        \"numbers\": re.findall(r\"\\d+\", a),\n",
    "        \"no_numbers\": [t for t in a.split() if str(t).isalpha()],\n",
    "        \"ud\": a_ud, \n",
    "        \"rae\": [x for x in a.split() if x in list_rae],\n",
    "        \"faces\": [f for f in generated_faces if f in \"\".join(a_org_tokens)],\n",
    "        \"slang\": [f for f in slang_C1 if f in \"\".join(a_org_tokens)],\n",
    "        \"keywords\": [f for f in keywords_C1 if f in \"\".join(a_org_tokens)],\n",
    "        \"lf_propn\": list({lf_w[0].lower() for lf_w in lf_a if lf_w[-1] == \"PROPN\"}),\n",
    "        \"lf_lemma\": list({lf_w[1].lower() for lf_w in lf_a}),\n",
    "        \"rel_subj\": list(set(rel_subj+[lf_w[0] for lf_w in lf_a if lf_w[-1] == \"PROPN\"])),\n",
    "        \"aux_tokens\": aux_list\n",
    "    }\n",
    "\n",
    "def get_simple_topo(dic_a):\n",
    "    a = dic_a[\"clean\"]\n",
    "    tokens = dic_a[\"tokens\"]\n",
    "    blank = dic_a[\"tokens\"]\n",
    "    numbers = dic_a[\"numbers\"]\n",
    "    digit = dic_a[\"digit\"]\n",
    "    o =  {\n",
    "        \"len\": len(a),\n",
    "        \"num_tokens\": len(tokens),\n",
    "        \"num_numbers\": len(numbers),\n",
    "        \"num_math_punct\": sum(dic_a[\"math_punct\"]),\n",
    "        \"num_digit\": sum(digit),\n",
    "        \"num_rae\": len(dic_a[\"rae\"]),\n",
    "        \"num_ud\": len(dic_a[\"ud\"]),\n",
    "        \"num_punct\": sum(dic_a[\"punct\"]),\n",
    "        \"num_slang\": len(dic_a[\"slang\"]),\n",
    "        \"num_faces\": len(dic_a[\"faces\"]),\n",
    "        \"num_keywords\": len(dic_a[\"keywords\"]),\n",
    "        \"num_no_numbers\": len(dic_a[\"no_numbers\"])\n",
    "    }\n",
    "    return o\n",
    "\n",
    "def get_ratio_vowel(dic_a):\n",
    "    a = dic_a[\"clean\"]\n",
    "    count_vowel = dic_a[\"vowel\"]\n",
    "    count_blank = dic_a[\"blank\"]\n",
    "    count_punct = dic_a[\"punct\"]\n",
    "    count_digit = dic_a[\"digit\"]\n",
    "    if sum(count_vowel) > 0:\n",
    "        return sum(count_vowel) / (len(a)-count_blank-sum(count_digit)-sum(count_punct))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_max_len_number(dic_a):\n",
    "    if dic_a[\"numbers\"]:\n",
    "        return max([len(n) for n in dic_a[\"numbers\"]])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_ratio_punct(dic_a, default=True):\n",
    "    a = dic_a[\"clean\"]\n",
    "    count_blank = dic_a[\"blank\"]\n",
    "    count_punct = dic_a[\"punct\"] if default else dic_a[\"math_punct\"]\n",
    "    if sum(count_punct) > 0:\n",
    "        return sum(count_punct) / (len(a)-count_blank)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_ratio_rae_ud(dic_a, l):\n",
    "    if l==\"rae\" and len(dic_a[\"org_tokens\"])>0:\n",
    "        return len(dic_a[l])/len(dic_a[\"org_tokens\"])\n",
    "    elif l==\"ud\" and len(dic_a[\"tokens\"])>0:\n",
    "        return len(dic_a[l])/len(dic_a[\"tokens\"])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_ratio_faces(dic_a):\n",
    "    if len(dic_a[\"org_tokens\"])>0:\n",
    "        return len(dic_a[\"faces\"]) / len(dic_a[\"org_tokens\"])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_ratio_slang(dic_a):\n",
    "    if len(dic_a[\"org_tokens\"])>0:\n",
    "        return len(dic_a[\"slang\"]) / len(dic_a[\"org_tokens\"])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_ratio_keywords(dic_a):\n",
    "    if len(dic_a[\"org_tokens\"])>0:\n",
    "        return len(dic_a[\"keywords\"]) / len(dic_a[\"org_tokens\"])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_ratio_no_numbers(dic_a):\n",
    "    if len(dic_a[\"org_tokens\"])>0:\n",
    "        return len(dic_a[\"no_numbers\"]) / len(dic_a[\"org_tokens\"])\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "def sim_lev(a, b):\n",
    "    return 1 - lev.distance(a, b) / max(len(a), len(b)) if len(a) != 0 else 0\n",
    "\n",
    "def get_injection_index(a, q):\n",
    "    relevant_words = [w for w in replace_multiple(unidecode(q).lower(), punct, \" \").split() if not w in spanish_stopwords]\n",
    "    theta = 0.7\n",
    "    tokens_a = a.split()\n",
    "    injection_index = 0\n",
    "    for k, t in enumerate(tokens_a):\n",
    "        for s in relevant_words:\n",
    "            if sim_lev(s, t) >= theta:\n",
    "                injection_index += 1\n",
    "                break\n",
    "        if len(tokens_a):\n",
    "            injection_index *= 1/len(relevant_words)\n",
    "    return injection_index\n",
    "\n",
    "def get_exist_numbs(dic_a, tresh=5):\n",
    "    num_numbers = len(dic_a[\"numbers\"])\n",
    "    if num_numbers == 0:\n",
    "        a = dic_a[\"clean\"]\n",
    "        if \"poco\" in a or \"mucho\" in a:\n",
    "            return 2\n",
    "        else:\n",
    "            return int(any([(d in a) for d in \"1234567890\"]))\n",
    "    else:\n",
    "        return int(max(len(str(n)) for n in dic_a[\"numbers\"])<tresh)\n",
    "    \n",
    "def get_sim_keywords(dic_a, keywords, theta=0.7):\n",
    "    a = dic_a[\"clean\"]\n",
    "    tokens_a = a.split()\n",
    "    injection_index = 0\n",
    "    for k, t in enumerate(tokens_a):\n",
    "        for s in keywords:\n",
    "            if sim_lev(s, t) >= theta:\n",
    "                injection_index += 1\n",
    "                break\n",
    "    return injection_index\n",
    "\n",
    "def get_sim_implication(dic_a, dic_q, typo=\"3\"):\n",
    "    # esta correcto lo que dijo/dice? not-!quién este en él correcto > (si, no)\n",
    "    # cual de las dos afirmaciones esta correcta? (alguna de las afirmaciones)\n",
    "    # quien esta en lo correcto? (quién estar en él correcto) > any PROPN\n",
    "    theta = 0.7\n",
    "    q_lemma = [w.replace(\",\", \"\").replace(\".\", \"\") for w in dic_q[\"lf_lemma\"]]\n",
    "    injection_index = 0\n",
    "    if typo==\"3\":\n",
    "        if ((\"ser\" in q_lemma or \"es\" in q_lemma or \"estar\" in q_lemma or \"este\" in q_lemma or \"esta\" in q_lemma) and \"correcto\" in q_lemma) or (\"tener\" in q_lemma and \"razón\" in q_lemma):\n",
    "            if (\"quién\" in q_lemma) or (\"cuál\" in q_lemma):\n",
    "                propn_q = dic_q[\"lf_propn\"]+[\"ninguno\",\"ninguna\", \"todos\",\"todas\", \"ambos\",\"ambas\", \"nadie\", \"alguno\", \"alguna\"]\n",
    "                tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"aux_tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "                for k, t in enumerate(tokens_a):\n",
    "                    t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                    for s in propn_q:\n",
    "                        if sim_lev(s, t) >= theta:\n",
    "                            injection_index += 1\n",
    "                            break\n",
    "            else:\n",
    "                tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "                for k, t in enumerate(tokens_a):\n",
    "                    t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                    for s in [\"falso\", \"verdadero\", \"sip\", \"nop\", \"estamal\", \"estabien\", \"bien\", \"mal\", \"si\", \"no\", \"correcta\", \"confundida\", \"confundido\", \"correcto\", \"equivocada\", \"equivocado\", \"incorrecta\", \"incorrecto\", \"razon\", \"razón\"]:\n",
    "                        if sim_lev(s, t) >= theta:\n",
    "                            injection_index += 1\n",
    "                            break\n",
    "        elif (\"por\" in q_lemma and \"qué\" in q_lemma and (\"ser\" in q_lemma or \"es\" in q_lemma or \"estar\" in q_lemma or \"este\" in q_lemma or \"esta\" in q_lemma) and (\"equivocado\" in q_lemma or \"equivocada\" in q_lemma)):\n",
    "            tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "            for k, t in enumerate(tokens_a):\n",
    "                t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                for s in [\"porque\", \"por\", \"que\", \"bien\", \"sip\", \"nop\", \"estamal\", \"estabien\", \"mal\", \"si\", \"no\", \"correcta\", \"confundida\", \"confundido\", \"correcto\", \"equivocada\", \"equivocado\", \"incorrecta\", \"incorrecto\", \"razon\", \"razón\"]:\n",
    "                    if sim_lev(s, t) >= theta:\n",
    "                        injection_index += 1\n",
    "                        break\n",
    "        elif (\"ser\" in q_lemma or \"es\" in q_lemma or \"estar\" in q_lemma or \"este\" in q_lemma or \"esta\" in q_lemma) and (\"bien\" in q_lemma):\n",
    "            tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "            for k, t in enumerate(tokens_a):\n",
    "                t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                for s in [\"verdadero\", \"falso\", \"bien\", \"mal\", \"si\", \"no\", \"correcta\", \"correcto\", \"equivocada\", \"equivocado\", \"confundida\", \"confundido\", \"incorrecta\", \"incorrecto\", \"razon\", \"razón\", \"sip\", \"nop\", \"estamal\", \"estabien\"]:\n",
    "                    if sim_lev(s, t) >= theta:\n",
    "                        injection_index += 1\n",
    "                        break\n",
    "    elif typo==\"4\":\n",
    "        if \"ser\" in q_lemma and \"posible\" in q_lemma:\n",
    "            tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "            for k, t in enumerate(tokens_a):\n",
    "                t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                for s in [\"verdadero\", \"falso\", \"bien\", \"mal\", \"si\", \"no\", \"correcta\", \"correcto\", \"equivocada\", \"equivocado\", \"confundida\", \"confundido\", \"incorrecta\", \"incorrecto\", \"razon\", \"razón\", \"sip\", \"nop\", \"estamal\", \"estabien\"]:\n",
    "                    if sim_lev(s, t) >= theta:\n",
    "                        injection_index += 1\n",
    "                        break\n",
    "            \n",
    "        elif \"quién\" in q_lemma or \"cuál\" in q_lemma or \"qué\" in q_lemma:\n",
    "            propn_q = dic_q[\"rel_subj\"]+[\"ninguno\",\"ninguna\", \"todos\",\"todas\", \"ambos\",\"ambas\", \"nadie\", \"alguno\", \"alguna\"]\n",
    "            tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"aux_tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "            for k, t in enumerate(tokens_a):\n",
    "                t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                for s in propn_q:\n",
    "                    if sim_lev(s, t) >= theta:\n",
    "                        injection_index += 1\n",
    "                        break\n",
    "    return injection_index\n",
    "\n",
    "def get_topo_features(a):\n",
    "    def get_crit_prop_vowel(w, prop_vowels):\n",
    "        if len(w.split()) == 1:\n",
    "            l_ = len(w.replace(\" \", \"\"))\n",
    "            if l_ and prop_vowels > 0.675:\n",
    "                return 1\n",
    "            elif w.isalpha():\n",
    "                l_prop = {5: 2/5, 6: 2/6, 7: 2/7, 8: 3/8, 9: 4/9, 10: 4/10, 11: 5/11, 12: 6/12, 13: 5/13, 14: 6/14, 15: 8/15, 16: 8/16, 17: 8/17, 18: 9/18, 19: 9/19, 20: 9/20}\n",
    "                if l_>21 and prop_vowels<1/2: \n",
    "                    return 1\n",
    "                elif 21>l_>4:\n",
    "                    return int(prop_vowels<l_prop[l_])\n",
    "        return 0\n",
    "\n",
    "    def get_prop_vowels(w):\n",
    "        N = len(a.replace(\" \", \"\"))\n",
    "        if N>0:\n",
    "            return sum( int(w in \"aeiou\") for w in a.replace(\" \", \"\")) / N\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def len_max_rep_char(w):\n",
    "        w=w+\" \"\n",
    "        c0 = w[0]\n",
    "        lens = [0]\n",
    "        clen = 1\n",
    "        for c in w[1:]:\n",
    "            if c == c0:\n",
    "                clen += 1\n",
    "            else:\n",
    "                if c0.isalpha():\n",
    "                    if clen>3 and c0 in [\"r\", \"l\", \"c\"]:\n",
    "                        lens.append(clen)\n",
    "                    elif clen>1:\n",
    "                        lens.append(clen)\n",
    "                c0 = c\n",
    "                clen = 1\n",
    "        return max(lens)  \n",
    "    \n",
    "    def max_char_fre_per_token(w, c=\"k\"):\n",
    "        tw = w.split()\n",
    "        fmax = 0\n",
    "        for t in tw:\n",
    "            f = sum(int(ch==c) for ch in t)\n",
    "            if f>fmax:\n",
    "                fmax = f\n",
    "        return fmax\n",
    "    \n",
    "    def max_type_rep_char_per_token(w, t=\"vowel\"):\n",
    "        w=unidecode(w+\" \")\n",
    "        c0 = w[0]\n",
    "        lens = [0]\n",
    "        clen = 1\n",
    "        for c in w[1:]:\n",
    "            if (c0.isalpha() and c.isalpha()) and ((c in \"aeiou\" and c0 in \"aeiou\") or (c not in \"aeiou\" and c0 not in \"aeiou\")):\n",
    "                clen += 1\n",
    "            else:\n",
    "                if t==\"vowel\":\n",
    "                    if c0 in \"aeiou\":\n",
    "                        lens.append(clen)\n",
    "                else:\n",
    "                    if c0 not in \"aeiou\":\n",
    "                        lens.append(clen) \n",
    "                c0 = c\n",
    "                clen = 1\n",
    "        return max(lens) \n",
    "    \n",
    "    a = str(a).replace(\"\\n\", \" \").lower()\n",
    "    a = \" \".join(a.split())\n",
    "    o = {}\n",
    "    \n",
    "    na = a.replace(\" \", \"\")\n",
    "    \n",
    "    o[\"traditional<&>len(~A)\"] = len(na)\n",
    "    o[\"traditional<&>prop_punct\"] = sum(int(w in punct) for w in na)/o[\"traditional<&>len(~A)\"] if o[\"traditional<&>len(~A)\"]>0 else 0\n",
    "    o[\"traditional<&>prop_punct+no-vowel\"] = sum(int(w in punct or (w not in \"aeiou\" and w.isalpha())) for w in na)/o[\"traditional<&>len(~A)\"] if o[\"traditional<&>len(~A)\"]>0 else 0\n",
    "    o[\"traditional<&>prop_vowels\"] = get_prop_vowels(a)\n",
    "    o[\"traditional<&>len(tokens(A))\"] = len(a.split())\n",
    "    o[\"traditional<&>len_max_rep_char\"] = len_max_rep_char(a)\n",
    "    o[\"semantic<&>A.isface()\"] = int(a in generated_faces and not a.isdigit() and a not in [\"ANA\", \"ana\"])\n",
    "    o[\"traditional<&>A.isdigit()\"] = int(na.isdigit())\n",
    "    o[\"traditional<&>frec_char(k)\"] = max_char_fre_per_token(a, c=\"k\")\n",
    "    o[\"traditional<&>frec_char(g)\"] = max_char_fre_per_token(a, c=\"g\")\n",
    "    o[\"traditional<&>frec_char(y)\"] = max_char_fre_per_token(a, c=\"y\")\n",
    "    o[\"traditional<&>frec_char(j)\"] = max_char_fre_per_token(a, c=\"j\")\n",
    "    o[\"traditional<&>frec_char(h)\"] = max_char_fre_per_token(a, c=\"h\")\n",
    "    o[\"traditional<&>frec_char(x)\"] = max_char_fre_per_token(a, c=\"x\")\n",
    "    o[\"traditional<&>frec_char(w)\"] = max_char_fre_per_token(a, c=\"w\")\n",
    "    o[\"traditional<&>frec_char(ñ)\"] = max_char_fre_per_token(a, c=\"ñ\")\n",
    "    o[\"semantic<&>A.is(nose)\"] = int(a == \"nose\")\n",
    "    o[\"traditional<&>A.is(nan)\"] = int(a == \"nan\")\n",
    "    o[\"semantic<&>A.is(ola|hola)\"] = int(a in [\"hola\", \"ola\"])\n",
    "    o[\"semantic<&>A.contains(bad-word)\"] = sum(int(w in bad_words) for w in a.split())\n",
    "    o[\"semantic<&>A.contains(punct_faces)\"] = sum(int(f in a) for f in punct_faces)\n",
    "    o[\"traditional<&>prop_punct+digit\"] = sum(int(w in punct or w.isdigit())for w in na)/o[\"traditional<&>len(~A)\"] if o[\"traditional<&>len(~A)\"]>0 else 0\n",
    "    o[\"traditional<&>prop_no_math_punct\"] = sum(int(w not in math_punct and w in punct )for w in na)/o[\"traditional<&>len(~A)\"] if o[\"traditional<&>len(~A)\"]>0 else 0\n",
    "    o[\"traditional<&>max_no-vowel_rep_char_per_token\"] = max_type_rep_char_per_token(a, \"\")\n",
    "    o[\"semantic<&>prop_no_digit_faces\"] = sum(int(t in no_digit_faces and t not in [\"ANA\", \"ana\"]) for t in a.split())/len(a.split()) if len(a.split())>0 else 0\n",
    "    o[\"semantic<&>prop_keywords\"] = sum(int(t in recurrent_words) for t in a.split())/len(a.split()) if len(a.split())>0 else 0\n",
    "    o[\"traditional<&>prop_digit_char\"] = sum(int(t.isdigit()) for t in na)/o[\"traditional<&>len(~A)\"] if o[\"traditional<&>len(~A)\"]>0 else 0\n",
    "    o[\"traditional<&>max_vowel_rep_char_per_token\"] = max_type_rep_char_per_token(a, \"vowel\")\n",
    "    o[\"traditional<&>prop_no_digit_no_math_punct\"] = sum(int(c in math_punct and not c.isdigit()) for c in a.replace(\" \", \"\"))/o[\"traditional<&>len(~A)\"] if o[\"traditional<&>len(~A)\"]>0 else 0\n",
    "    o[\"traditional<&>num_alpha\"] = sum(int(t.isalpha()) for t in a.replace(\" \", \"\"))\n",
    "    o[\"traditional<&>prop_alpha_vowels\"] = sum(int(t in \"aeiou\") for t in a.replace(\" \", \"\"))/o[\"traditional<&>num_alpha\"] if o[\"traditional<&>num_alpha\"]>0 else 0\n",
    "    \n",
    "    return o\n",
    "\n",
    "def get_overlap_by(dic_a, dic_q, by=\"\"): #Q[propn+]&A, Q[quién|cuál|qué], Q[ser&posible], A[binary(si|no)]\n",
    "    theta = 0.7\n",
    "    injection_index = 0\n",
    "    if \"Q\" in by and \"A\" not in by:\n",
    "        q_lemma = [w.replace(\",\", \"\").replace(\".\", \"\") for w in dic_q[\"lf_lemma\"]]\n",
    "        if by == \"Q[quién|cuál|qué]\":\n",
    "            if \"quién\" in q_lemma or \"cuál\" in q_lemma or \"qué\" in q_lemma:\n",
    "                injection_index = 1\n",
    "        elif by == \"Q[ser&posible]\":\n",
    "            if \"ser\" in q_lemma and \"posible\" in q_lemma:\n",
    "                injection_index = 1\n",
    "        elif by == \"Q[(ser*&correcto)|(tener&razón)]\":\n",
    "            if ((\"ser\" in q_lemma or \"es\" in q_lemma or \"estar\" in q_lemma or \"este\" in q_lemma or \"esta\" in q_lemma) and \"correcto\" in q_lemma) or (\"tener\" in q_lemma and \"razón\" in q_lemma):\n",
    "                injection_index = 1\n",
    "        elif by == \"Q[ser*&correcto]\":\n",
    "            if (\"ser\" in q_lemma or \"es\" in q_lemma or \"estar\" in q_lemma or \"este\" in q_lemma or \"esta\" in q_lemma) and \"correcto\" in q_lemma:\n",
    "                injection_index = 1\n",
    "        elif  by == \"Q[tener&razón]\":\n",
    "             if \"tener\" in q_lemma and \"razón\" in q_lemma:\n",
    "                injection_index = 1\n",
    "        elif by == \"Q[quién|cuál]\":\n",
    "            if \"quién\" in q_lemma or \"cuál\":\n",
    "                injection_index = 1\n",
    "        elif by == \"Q[ser*&bien]\":\n",
    "            if (\"ser\" in q_lemma or \"es\" in q_lemma or \"estar\" in q_lemma or \"este\" in q_lemma or \"esta\" in q_lemma) and \"bien\" in q_lemma:\n",
    "                injection_index = 1\n",
    "        elif by == \"Q[por&qué&ser*&equivocado]\":\n",
    "            if \"por\" in q_lemma and \"qué\" in q_lemma and (\"ser\" in q_lemma or \"es\" in q_lemma or \"estar\" in q_lemma or \"este\" in q_lemma or \"esta\" in q_lemma) and (\"equivocado\" in q_lemma or \"equivocada\" in q_lemma):\n",
    "                injection_index = 1\n",
    "        elif by == \"Q[por&qué&equivocado]\":\n",
    "            if \"por\" in q_lemma and \"qué\" in q_lemma  and (\"equivocado\" in q_lemma or \"equivocada\" in q_lemma):\n",
    "                injection_index = 1\n",
    "        \n",
    "        \n",
    "    elif \"A\" in by and \"Q\" not in by:\n",
    "        tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "        if by == \"A[binary(si|no)]\":\n",
    "            for k, t in enumerate(tokens_a):\n",
    "                t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                for s in [\"verdadero\", \"falso\", \"bien\", \"mal\", \"si\", \"no\", \"correcta\", \"correcto\", \"equivocada\", \"equivocado\", \"incorrecta\", \"confundida\", \"confundido\", \"incorrecto\", \"razon\", \"razón\", \"sip\", \"nop\", \"estamal\", \"estabien\"]:\n",
    "                    if sim_lev(s, t) >= theta:\n",
    "                        injection_index += 1\n",
    "                        break\n",
    "        if by == \"A[porque|binary(si, no)]\":\n",
    "            for k, t in enumerate(tokens_a):\n",
    "                t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                for s in [\"porque\", \"por\", \"que\", \"bien\", \"sip\", \"nop\", \"estamal\", \"estabien\", \"mal\", \"si\", \"no\", \"correcta\", \"correcto\", \"confundida\", \"confundido\", \"equivocada\", \"equivocado\", \"incorrecta\", \"incorrecto\", \"razon\", \"razón\"]:\n",
    "                    if sim_lev(s, t) >= theta:\n",
    "                        injection_index += 1\n",
    "                        break\n",
    "    elif \"A\" in by and \"Q\" in by:\n",
    "        if by == \"Q[rel_subj]+&A+\":\n",
    "            propn_q = dic_q[\"rel_subj\"]+[\"ninguno\",\"ninguna\", \"todos\",\"todas\", \"ambos\",\"ambas\", \"nadie\", \"alguno\", \"alguna\"]\n",
    "            tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"aux_tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "            for k, t in enumerate(tokens_a):\n",
    "                t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                for s in propn_q:\n",
    "                    if sim_lev(s, t) >= theta:\n",
    "                        injection_index += 1\n",
    "                        break\n",
    "        if by == \"Q[propn]+&A+\":\n",
    "            propn_q = dic_q[\"rel_subj\"]+[\"ninguno\",\"ninguna\", \"todos\",\"todas\", \"ambos\",\"ambas\", \"nadie\", \"alguno\", \"alguna\"]\n",
    "            tokens_a = set(dic_a[\"org_tokens\"]+dic_a[\"tokens\"]+dic_a[\"aux_tokens\"]+dic_a[\"lower_org_tokens\"]+dic_a[\"org_tokens_wo_punct\"])\n",
    "            for k, t in enumerate(tokens_a):\n",
    "                t = t.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                for s in propn_q:\n",
    "                    if sim_lev(s, t) >= theta:\n",
    "                        injection_index += 1\n",
    "                        break\n",
    "    return injection_index\n",
    "\n",
    "class Preprocessing(object):\n",
    "    def __init__(self):\n",
    "        self.dic_comparison = {}\n",
    "        self.dic_lf = {}\n",
    "        self.dic_topo = {}\n",
    "        self.dic_attrib = {\"a\": {}, \"q\": {}}\n",
    "        self.dic_features = {}\n",
    "        self.dic_simple_topo = {}\n",
    "    \n",
    "    def get_dic_attrib(self, t, ix, a):\n",
    "#         print(t, ix, a)\n",
    "        if ix not in self.dic_attrib[t].keys():    \n",
    "            self.dic_attrib[t][ix] = get_attrib(a)\n",
    "        return self.dic_attrib[t][ix]\n",
    "            \n",
    "    def get_lf(self, ix, a):\n",
    "        a = \"\" if a == \"nan\" else a\n",
    "        a = a.replace(\"\\n\", \" \")\n",
    "        a = \" \".join(a.split())\n",
    "        if ix not in self.dic_lf.keys():\n",
    "            o = {}\n",
    "            doc_a = nlp(a)   \n",
    "            num_tokens = len(doc_a)\n",
    "            o[\"traditional<&>num_tokens\"] = num_tokens\n",
    "            for token in doc_a:\n",
    "                dic_lf = {\n",
    "#                     \"lemma\": token.lemma_,\n",
    "                    \"tag\": token.tag_,\n",
    "                    \"dep\": token.dep_,\n",
    "                    \"shape\": token.shape_,\n",
    "                    \"is_alpha\": token.is_alpha,\n",
    "                    \"is_stop\": token.is_stop\n",
    "                }\n",
    "                for k, v in dic_lf.items():\n",
    "                    name_col = f\"linguistic<&>{k}<&>{v}\"\n",
    "                    if name_col not in o.keys():\n",
    "                        o[name_col] = 0\n",
    "                    o[name_col] += 1\n",
    "                    \n",
    "                    if k == \"shape\":\n",
    "                        if v != \"\" and unidecode(v) == \"\":\n",
    "                            name_col = f\"linguistic<&>{k}<&>emoji\"\n",
    "                            if name_col not in o.keys():\n",
    "                                o[name_col] = 0\n",
    "                            o[name_col] += 1 \n",
    "                        else:\n",
    "                            for c in set(v):\n",
    "                                name_col = f\"linguistic<&>{k}<&>contains({c})\"\n",
    "                                if c in \"\"\"!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\"\"\":\n",
    "                                    name_col = f\"linguistic<&>{k}<&>contains(punct)\"\n",
    "                                \n",
    "                                if name_col not in o.keys():\n",
    "                                    o[name_col] = 0\n",
    "                                o[name_col] += 1\n",
    "\n",
    "            for k, v in o.copy().items():\n",
    "                if (k != \"traditional<&>num_tokens\") and (\"linguistic<&>lemma<&>\" not in k) and ((\"linguistic<&>shape<&>\" not in k) or (\"linguistic<&>shape<&>\" in k and k.split(\"<&>\")[2] in [\"emoji\", \"contains(x)\", \"contains(d)\", \"contains(punct)\"])):\n",
    "                    nk = k.replace(\"traditional<&>\", \"\").replace(\"linguistic<&>\", \"\")\n",
    "                    o[f\"linguistic<&>ratio({nk}/num_tokens)\"] = v/o[\"traditional<&>num_tokens\"] if o[\"traditional<&>num_tokens\"]!= 0 else 0\n",
    "                    \n",
    "            self.dic_lf[ix] = o\n",
    "        return self.dic_lf[ix]\n",
    "        \n",
    "    def get_representation(self, ixa, ixq, a, q):\n",
    "        ix = f\"{ixa}_{ixq}\" \n",
    "        if ix not in self.dic_comparison.keys():\n",
    "            dic_a = self.get_dic_attrib(\"a\", ixa, a)  \n",
    "            dic_q = self.get_dic_attrib(\"q\", ixq, q)  \n",
    "            o = {}\n",
    "            o[\"contextual<&>Q[rel_subj]+&A+\"] = get_overlap_by(dic_a, dic_q, \"Q[rel_subj]+&A+\")\n",
    "            o[\"contextual<&>Q[quién|cuál|qué]\"] = get_overlap_by(None, dic_q, \"Q[quién|cuál|qué]\")\n",
    "            o[\"contextual<&>Q[ser&posible]\"] = get_overlap_by(None, dic_q, \"Q[ser&posible]\")\n",
    "            o[\"contextual<&>A[binary(si|no)]\"] = get_overlap_by(dic_a, None, \"A[binary(si|no)]\")\n",
    "\n",
    "            o[\"contextual<&>Q[por&qué&equivocado]\"] = get_overlap_by(None, dic_q, \"Q[por&qué&equivocado]\")\n",
    "            o[\"contextual<&>Q[ser*&bien]\"] = get_overlap_by(None, dic_q, \"Q[ser*&bien]\")\n",
    "            o[\"contextual<&>A[porque|binary(si|no)]\"] = get_overlap_by(dic_a, None, \"A[porque|binary(si|no)]\")\n",
    "            o[\"contextual<&>Q[propn]+&A+\"] = get_overlap_by(dic_a, dic_q, \"Q[propn]+&A+\")\n",
    "            o[\"contextual<&>Q[quién|cuál]\"] = get_overlap_by(None, dic_q, \"Q[quién|cuál]\")\n",
    "            o[\"contextual<&>Q[(ser*&correcto)|(tener&razón)]\"] = get_overlap_by(None, dic_q, \"Q[(ser*&correcto)|(tener&razón)]\")\n",
    "            o[\"contextual<&>Q[ser*&correcto]\"] = get_overlap_by(None, dic_q, \"Q[ser*&correcto]\")\n",
    "            o[\"contextual<&>Q[tener&razón]\"]= get_overlap_by(None, dic_q, \"Q[tener&razón]\")\n",
    "\n",
    "            o[\"contextual<&>injection_index\"] = get_injection_index(str(a), str(q))\n",
    "            self.dic_comparison[ix] = o\n",
    "        return self.dic_comparison[ix] \n",
    "            \n",
    "    def get_preprocessing(self, D):\n",
    "        data_representations = []\n",
    "        _times = []\n",
    "        for k, ixa in enumerate(D.index):\n",
    "            start = time.time()\n",
    "            a = D.loc[ixa][\"A\"]\n",
    "            a = str(a)\n",
    "            q = D.loc[ixa][\"Q\"]\n",
    "            q = str(q) \n",
    "            ixq = D.loc[ixa][\"Q_id\"]\n",
    "            o = self.get_features(ixa, ixq, a, q)\n",
    "            data_representations.append(o)\n",
    "            end = time.time()\n",
    "            _times.append(end-start)\n",
    "            time_expected = (len(D.index)-(k+1))*np.mean(_times)\n",
    "            time_expected_min = np.floor(time_expected/60)\n",
    "            time_expected_sec = time_expected - time_expected_min*60\n",
    "            if k % 100 == 0 or k==len(D.index)-1:\n",
    "                print(f\"\"\"{k+1}/{len(D.index)}, progress: {100*(k+1)/len(D.index): .2f} %, dt: {_times[-1]: .2f}, exp. dt: {np.mean(_times): .2f} p/m {np.std(_times): .2f} s, t. trans: {np.sum(_times)/60: .1f} min, t. exp. end: {time_expected_min: .1f} m {time_expected_sec: .1f} s\"\"\")            \n",
    "        df_representation = pd.DataFrame(data_representations, index=D.index)\n",
    "        fillna_0 = [\"linguistic<&>\"]\n",
    "        dic_fillna = {c: 0 for c in df_representation.columns if any(x in c for x in fillna_0)}\n",
    "        df_representation = df_representation.fillna(dic_fillna)\n",
    "        return df_representation\n",
    "    \n",
    "    def get_topo(self, ix, a):\n",
    "        if ix not in self.dic_topo.keys():\n",
    "            self.dic_topo[ix] = get_topo_features(a)\n",
    "        return self.dic_topo[ix]   \n",
    "     \n",
    "    def get_simple_topo(self, ix, a):\n",
    "        if ix not in self.dic_simple_topo.keys():\n",
    "            dic_a = self.get_dic_attrib(\"a\", ix, a)   \n",
    "            self.dic_simple_topo[ix] = get_simple_topo(dic_a)\n",
    "        return self.dic_simple_topo[ix]   \n",
    "        \n",
    "    def get_features(self, ixa, ixq, a, q):\n",
    "            ix = f\"{ixa}_{ixq}\"\n",
    "            if ix not in self.dic_features.keys():\n",
    "                o = self.get_representation(ixa, ixq, a, q)\n",
    "                \n",
    "                o = {**o, **self.get_topo(ixa, a)}\n",
    "                o = {**o, **self.get_lf(ixa, a)}\n",
    "                dic_a = self.get_dic_attrib(\"a\", ixa, a)   \n",
    "                for k, v in self.get_simple_topo(ixa, a).items():\n",
    "                    if k in [\n",
    "                             'len',\n",
    "                             'num_digit',\n",
    "                             'num_math_punct',\n",
    "                             'num_no_numbers',\n",
    "                             'num_numbers',\n",
    "                             'num_punct',\n",
    "                             'num_tokens',\n",
    "                    ]: o[\"traditional<&>\"+k] = v\n",
    "                    elif k in [\n",
    "                        'num_keywords',\n",
    "                        'num_rae',\n",
    "                        'num_ud',\n",
    "                        'num_slang',\n",
    "                        'num_faces'\n",
    "                    ]: o[\"semantic<&>\"+k] = v\n",
    "                    \n",
    "                o[\"semantic<&>ratio_rae\"] = get_ratio_rae_ud(dic_a, \"rae\")\n",
    "                o[\"semantic<&>ratio_ud\"] = get_ratio_rae_ud(dic_a, \"ud\")                \n",
    "                o[\"semantic<&>ratio_slang\"] = get_ratio_slang(dic_a)\n",
    "                o[\"semantic<&>ratio_keywords\"] = get_ratio_keywords(dic_a)\n",
    "                o[\"semantic<&>ratio_faces\"] = get_ratio_faces(dic_a)\n",
    "                \n",
    "                o[\"traditional<&>ratio_vowel\"] = get_ratio_vowel(dic_a)\n",
    "                o[\"traditional<&>ratio_no_numbers\"] = get_ratio_no_numbers(dic_a)\n",
    "                o[\"traditional<&>ratio_punct\"] =  get_ratio_punct(dic_a, default=True)\n",
    "                o[\"traditional<&>exist_numbs\"] =  get_exist_numbs(dic_a)\n",
    "                o[\"traditional<&>max_len_number\"] = get_max_len_number(dic_a)\n",
    "                \n",
    "                self.dic_features[ix] = o\n",
    "            return self.dic_features[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad6b0cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/111316, progress:  0.00 %, dt:  0.28, exp. dt:  0.28 p/m  0.00 s, t. trans:  0.0 min, t. exp. end:  528.0 m  43.5 s\n",
      "101/111316, progress:  0.09 %, dt:  0.16, exp. dt:  0.15 p/m  0.04 s, t. trans:  0.3 min, t. exp. end:  281.0 m  13.2 s\n",
      "201/111316, progress:  0.18 %, dt:  0.11, exp. dt:  0.14 p/m  0.04 s, t. trans:  0.5 min, t. exp. end:  268.0 m  0.7 s\n",
      "301/111316, progress:  0.27 %, dt:  0.15, exp. dt:  0.14 p/m  0.04 s, t. trans:  0.7 min, t. exp. end:  259.0 m  9.9 s\n",
      "401/111316, progress:  0.36 %, dt:  0.16, exp. dt:  0.14 p/m  0.04 s, t. trans:  0.9 min, t. exp. end:  261.0 m  0.8 s\n",
      "501/111316, progress:  0.45 %, dt:  0.13, exp. dt:  0.14 p/m  0.04 s, t. trans:  1.2 min, t. exp. end:  261.0 m  59.6 s\n",
      "601/111316, progress:  0.54 %, dt:  0.18, exp. dt:  0.14 p/m  0.04 s, t. trans:  1.4 min, t. exp. end:  256.0 m  36.7 s\n",
      "701/111316, progress:  0.63 %, dt:  0.10, exp. dt:  0.14 p/m  0.04 s, t. trans:  1.6 min, t. exp. end:  253.0 m  21.3 s\n",
      "801/111316, progress:  0.72 %, dt:  0.12, exp. dt:  0.14 p/m  0.04 s, t. trans:  1.9 min, t. exp. end:  256.0 m  55.3 s\n",
      "901/111316, progress:  0.81 %, dt:  0.09, exp. dt:  0.14 p/m  0.04 s, t. trans:  2.1 min, t. exp. end:  253.0 m  53.2 s\n",
      "1001/111316, progress:  0.90 %, dt:  0.10, exp. dt:  0.14 p/m  0.04 s, t. trans:  2.3 min, t. exp. end:  251.0 m  40.3 s\n",
      "1101/111316, progress:  0.99 %, dt:  0.11, exp. dt:  0.14 p/m  0.04 s, t. trans:  2.5 min, t. exp. end:  249.0 m  43.1 s\n",
      "1201/111316, progress:  1.08 %, dt:  0.12, exp. dt:  0.14 p/m  0.04 s, t. trans:  2.7 min, t. exp. end:  251.0 m  35.8 s\n",
      "1301/111316, progress:  1.17 %, dt:  0.22, exp. dt:  0.14 p/m  0.04 s, t. trans:  3.0 min, t. exp. end:  250.0 m  44.7 s\n",
      "1401/111316, progress:  1.26 %, dt:  0.23, exp. dt:  0.14 p/m  0.04 s, t. trans:  3.2 min, t. exp. end:  249.0 m  9.9 s\n",
      "1501/111316, progress:  1.35 %, dt:  0.18, exp. dt:  0.13 p/m  0.04 s, t. trans:  3.4 min, t. exp. end:  246.0 m  58.5 s\n",
      "1601/111316, progress:  1.44 %, dt:  0.12, exp. dt:  0.14 p/m  0.04 s, t. trans:  3.6 min, t. exp. end:  246.0 m  53.0 s\n",
      "1701/111316, progress:  1.53 %, dt:  0.12, exp. dt:  0.13 p/m  0.04 s, t. trans:  3.8 min, t. exp. end:  245.0 m  10.0 s\n",
      "1801/111316, progress:  1.62 %, dt:  0.12, exp. dt:  0.13 p/m  0.04 s, t. trans:  4.0 min, t. exp. end:  244.0 m  2.9 s\n",
      "1901/111316, progress:  1.71 %, dt:  0.11, exp. dt:  0.13 p/m  0.04 s, t. trans:  4.2 min, t. exp. end:  242.0 m  52.2 s\n",
      "2001/111316, progress:  1.80 %, dt:  0.13, exp. dt:  0.13 p/m  0.04 s, t. trans:  4.5 min, t. exp. end:  243.0 m  8.3 s\n",
      "2101/111316, progress:  1.89 %, dt:  0.13, exp. dt:  0.13 p/m  0.04 s, t. trans:  4.7 min, t. exp. end:  242.0 m  14.8 s\n",
      "2201/111316, progress:  1.98 %, dt:  0.13, exp. dt:  0.13 p/m  0.03 s, t. trans:  4.9 min, t. exp. end:  241.0 m  32.5 s\n",
      "2301/111316, progress:  2.07 %, dt:  0.16, exp. dt:  0.13 p/m  0.04 s, t. trans:  5.1 min, t. exp. end:  242.0 m  21.8 s\n",
      "2401/111316, progress:  2.16 %, dt:  0.10, exp. dt:  0.13 p/m  0.04 s, t. trans:  5.3 min, t. exp. end:  242.0 m  38.3 s\n",
      "2501/111316, progress:  2.25 %, dt:  0.15, exp. dt:  0.13 p/m  0.04 s, t. trans:  5.6 min, t. exp. end:  242.0 m  54.3 s\n",
      "2601/111316, progress:  2.34 %, dt:  0.11, exp. dt:  0.13 p/m  0.04 s, t. trans:  5.8 min, t. exp. end:  242.0 m  53.8 s\n",
      "2701/111316, progress:  2.43 %, dt:  0.11, exp. dt:  0.13 p/m  0.03 s, t. trans:  6.0 min, t. exp. end:  242.0 m  5.3 s\n",
      "2801/111316, progress:  2.52 %, dt:  0.12, exp. dt:  0.13 p/m  0.03 s, t. trans:  6.2 min, t. exp. end:  241.0 m  56.8 s\n",
      "2901/111316, progress:  2.61 %, dt:  0.19, exp. dt:  0.13 p/m  0.03 s, t. trans:  6.5 min, t. exp. end:  241.0 m  36.4 s\n",
      "3001/111316, progress:  2.70 %, dt:  0.13, exp. dt:  0.13 p/m  0.04 s, t. trans:  6.7 min, t. exp. end:  241.0 m  3.1 s\n",
      "3101/111316, progress:  2.79 %, dt:  0.12, exp. dt:  0.13 p/m  0.04 s, t. trans:  6.9 min, t. exp. end:  241.0 m  28.3 s\n",
      "3201/111316, progress:  2.88 %, dt:  0.10, exp. dt:  0.13 p/m  0.04 s, t. trans:  7.1 min, t. exp. end:  241.0 m  4.3 s\n",
      "3301/111316, progress:  2.97 %, dt:  0.11, exp. dt:  0.13 p/m  0.04 s, t. trans:  7.3 min, t. exp. end:  240.0 m  22.7 s\n",
      "3401/111316, progress:  3.06 %, dt:  0.12, exp. dt:  0.13 p/m  0.03 s, t. trans:  7.6 min, t. exp. end:  240.0 m  12.5 s\n",
      "3501/111316, progress:  3.15 %, dt:  0.14, exp. dt:  0.13 p/m  0.03 s, t. trans:  7.8 min, t. exp. end:  239.0 m  53.9 s\n",
      "3601/111316, progress:  3.23 %, dt:  0.12, exp. dt:  0.13 p/m  0.03 s, t. trans:  8.0 min, t. exp. end:  240.0 m  28.2 s\n",
      "3701/111316, progress:  3.32 %, dt:  0.16, exp. dt:  0.13 p/m  0.03 s, t. trans:  8.3 min, t. exp. end:  240.0 m  40.9 s\n",
      "3801/111316, progress:  3.41 %, dt:  0.13, exp. dt:  0.13 p/m  0.03 s, t. trans:  8.5 min, t. exp. end:  241.0 m  2.6 s\n",
      "3901/111316, progress:  3.50 %, dt:  0.17, exp. dt:  0.13 p/m  0.04 s, t. trans:  8.8 min, t. exp. end:  241.0 m  27.4 s\n",
      "4001/111316, progress:  3.59 %, dt:  0.13, exp. dt:  0.14 p/m  0.04 s, t. trans:  9.0 min, t. exp. end:  242.0 m  12.1 s\n",
      "4101/111316, progress:  3.68 %, dt:  0.13, exp. dt:  0.14 p/m  0.04 s, t. trans:  9.3 min, t. exp. end:  242.0 m  27.7 s\n",
      "4201/111316, progress:  3.77 %, dt:  0.17, exp. dt:  0.14 p/m  0.04 s, t. trans:  9.5 min, t. exp. end:  242.0 m  31.7 s\n",
      "4301/111316, progress:  3.86 %, dt:  0.12, exp. dt:  0.14 p/m  0.04 s, t. trans:  9.8 min, t. exp. end:  242.0 m  38.5 s\n",
      "4401/111316, progress:  3.95 %, dt:  0.16, exp. dt:  0.14 p/m  0.04 s, t. trans:  10.0 min, t. exp. end:  243.0 m  0.8 s\n",
      "4501/111316, progress:  4.04 %, dt:  0.12, exp. dt:  0.14 p/m  0.04 s, t. trans:  10.2 min, t. exp. end:  242.0 m  59.6 s\n",
      "4601/111316, progress:  4.13 %, dt:  0.14, exp. dt:  0.14 p/m  0.04 s, t. trans:  10.5 min, t. exp. end:  243.0 m  23.2 s\n",
      "4701/111316, progress:  4.22 %, dt:  0.13, exp. dt:  0.14 p/m  0.04 s, t. trans:  10.7 min, t. exp. end:  243.0 m  6.2 s\n",
      "4801/111316, progress:  4.31 %, dt:  0.09, exp. dt:  0.14 p/m  0.04 s, t. trans:  11.0 min, t. exp. end:  243.0 m  16.9 s\n",
      "4901/111316, progress:  4.40 %, dt:  0.16, exp. dt:  0.14 p/m  0.04 s, t. trans:  11.2 min, t. exp. end:  242.0 m  55.7 s\n",
      "5001/111316, progress:  4.49 %, dt:  0.20, exp. dt:  0.14 p/m  0.04 s, t. trans:  11.5 min, t. exp. end:  243.0 m  25.6 s\n",
      "5101/111316, progress:  4.58 %, dt:  0.16, exp. dt:  0.14 p/m  0.04 s, t. trans:  11.7 min, t. exp. end:  243.0 m  6.2 s\n",
      "5201/111316, progress:  4.67 %, dt:  0.13, exp. dt:  0.14 p/m  0.04 s, t. trans:  11.9 min, t. exp. end:  243.0 m  8.6 s\n",
      "5301/111316, progress:  4.76 %, dt:  0.33, exp. dt:  0.14 p/m  0.04 s, t. trans:  12.2 min, t. exp. end:  243.0 m  0.9 s\n",
      "5401/111316, progress:  4.85 %, dt:  0.11, exp. dt:  0.14 p/m  0.04 s, t. trans:  12.4 min, t. exp. end:  243.0 m  6.1 s\n",
      "5501/111316, progress:  4.94 %, dt:  0.18, exp. dt:  0.14 p/m  0.04 s, t. trans:  12.6 min, t. exp. end:  243.0 m  5.7 s\n",
      "5601/111316, progress:  5.03 %, dt:  0.11, exp. dt:  0.14 p/m  0.04 s, t. trans:  12.9 min, t. exp. end:  243.0 m  4.9 s\n",
      "5701/111316, progress:  5.12 %, dt:  0.17, exp. dt:  0.14 p/m  0.04 s, t. trans:  13.1 min, t. exp. end:  243.0 m  25.8 s\n",
      "5801/111316, progress:  5.21 %, dt:  0.16, exp. dt:  0.14 p/m  0.04 s, t. trans:  13.4 min, t. exp. end:  243.0 m  8.7 s\n",
      "5901/111316, progress:  5.30 %, dt:  0.18, exp. dt:  0.14 p/m  0.04 s, t. trans:  13.6 min, t. exp. end:  243.0 m  8.5 s\n",
      "6001/111316, progress:  5.39 %, dt:  0.10, exp. dt:  0.14 p/m  0.04 s, t. trans:  13.8 min, t. exp. end:  242.0 m  31.9 s\n",
      "6101/111316, progress:  5.48 %, dt:  0.12, exp. dt:  0.14 p/m  0.11 s, t. trans:  14.2 min, t. exp. end:  244.0 m  57.0 s\n",
      "6201/111316, progress:  5.57 %, dt:  0.20, exp. dt:  0.14 p/m  0.11 s, t. trans:  14.4 min, t. exp. end:  244.0 m  33.0 s\n",
      "6301/111316, progress:  5.66 %, dt:  0.13, exp. dt:  0.14 p/m  0.11 s, t. trans:  14.7 min, t. exp. end:  244.0 m  41.6 s\n",
      "6401/111316, progress:  5.75 %, dt:  0.14, exp. dt:  0.14 p/m  0.11 s, t. trans:  14.9 min, t. exp. end:  244.0 m  23.5 s\n",
      "6501/111316, progress:  5.84 %, dt:  0.14, exp. dt:  0.14 p/m  0.11 s, t. trans:  15.2 min, t. exp. end:  244.0 m  33.4 s\n",
      "6601/111316, progress:  5.93 %, dt:  0.19, exp. dt:  0.14 p/m  0.11 s, t. trans:  15.4 min, t. exp. end:  244.0 m  19.2 s\n",
      "6701/111316, progress:  6.02 %, dt:  0.12, exp. dt:  0.14 p/m  0.11 s, t. trans:  15.6 min, t. exp. end:  244.0 m  16.4 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6801/111316, progress:  6.11 %, dt:  0.17, exp. dt:  0.14 p/m  0.10 s, t. trans:  15.9 min, t. exp. end:  243.0 m  60.0 s\n",
      "6901/111316, progress:  6.20 %, dt:  0.19, exp. dt:  0.14 p/m  0.10 s, t. trans:  16.1 min, t. exp. end:  243.0 m  57.0 s\n",
      "7001/111316, progress:  6.29 %, dt:  0.14, exp. dt:  0.14 p/m  0.10 s, t. trans:  16.4 min, t. exp. end:  244.0 m  32.6 s\n",
      "7101/111316, progress:  6.38 %, dt:  0.18, exp. dt:  0.14 p/m  0.10 s, t. trans:  16.7 min, t. exp. end:  245.0 m  0.9 s\n",
      "7201/111316, progress:  6.47 %, dt:  0.18, exp. dt:  0.14 p/m  0.10 s, t. trans:  17.0 min, t. exp. end:  245.0 m  30.9 s\n",
      "7301/111316, progress:  6.56 %, dt:  0.12, exp. dt:  0.14 p/m  0.10 s, t. trans:  17.2 min, t. exp. end:  245.0 m  24.6 s\n",
      "7401/111316, progress:  6.65 %, dt:  0.15, exp. dt:  0.14 p/m  0.10 s, t. trans:  17.5 min, t. exp. end:  245.0 m  28.6 s\n",
      "7501/111316, progress:  6.74 %, dt:  0.17, exp. dt:  0.14 p/m  0.10 s, t. trans:  17.7 min, t. exp. end:  245.0 m  22.9 s\n",
      "7601/111316, progress:  6.83 %, dt:  0.14, exp. dt:  0.14 p/m  0.10 s, t. trans:  18.0 min, t. exp. end:  245.0 m  57.1 s\n",
      "7701/111316, progress:  6.92 %, dt:  0.14, exp. dt:  0.14 p/m  0.10 s, t. trans:  18.3 min, t. exp. end:  246.0 m  16.1 s\n",
      "7801/111316, progress:  7.01 %, dt:  0.16, exp. dt:  0.14 p/m  0.10 s, t. trans:  18.6 min, t. exp. end:  246.0 m  19.6 s\n",
      "7901/111316, progress:  7.10 %, dt:  0.12, exp. dt:  0.14 p/m  0.10 s, t. trans:  18.8 min, t. exp. end:  246.0 m  4.8 s\n",
      "8001/111316, progress:  7.19 %, dt:  0.14, exp. dt:  0.14 p/m  0.10 s, t. trans:  19.0 min, t. exp. end:  245.0 m  54.6 s\n",
      "8101/111316, progress:  7.28 %, dt:  0.13, exp. dt:  0.14 p/m  0.10 s, t. trans:  19.3 min, t. exp. end:  245.0 m  40.8 s\n",
      "8201/111316, progress:  7.37 %, dt:  0.15, exp. dt:  0.14 p/m  0.10 s, t. trans:  19.5 min, t. exp. end:  245.0 m  27.2 s\n",
      "8301/111316, progress:  7.46 %, dt:  0.13, exp. dt:  0.14 p/m  0.10 s, t. trans:  19.8 min, t. exp. end:  245.0 m  35.6 s\n",
      "8401/111316, progress:  7.55 %, dt:  0.31, exp. dt:  0.14 p/m  0.10 s, t. trans:  20.0 min, t. exp. end:  245.0 m  30.7 s\n",
      "8501/111316, progress:  7.64 %, dt:  0.17, exp. dt:  0.14 p/m  0.10 s, t. trans:  20.3 min, t. exp. end:  245.0 m  19.2 s\n",
      "8601/111316, progress:  7.73 %, dt:  0.12, exp. dt:  0.14 p/m  0.10 s, t. trans:  20.5 min, t. exp. end:  245.0 m  20.3 s\n",
      "8701/111316, progress:  7.82 %, dt:  0.16, exp. dt:  0.14 p/m  0.09 s, t. trans:  20.8 min, t. exp. end:  245.0 m  6.9 s\n",
      "8801/111316, progress:  7.91 %, dt:  0.12, exp. dt:  0.14 p/m  0.09 s, t. trans:  21.0 min, t. exp. end:  245.0 m  2.2 s\n",
      "8901/111316, progress:  8.00 %, dt:  0.14, exp. dt:  0.14 p/m  0.09 s, t. trans:  21.3 min, t. exp. end:  244.0 m  40.6 s\n",
      "9001/111316, progress:  8.09 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  21.5 min, t. exp. end:  244.0 m  29.1 s\n",
      "9101/111316, progress:  8.18 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  21.8 min, t. exp. end:  244.0 m  23.1 s\n",
      "9201/111316, progress:  8.27 %, dt:  0.18, exp. dt:  0.14 p/m  0.09 s, t. trans:  22.0 min, t. exp. end:  244.0 m  20.6 s\n",
      "9301/111316, progress:  8.36 %, dt:  0.11, exp. dt:  0.14 p/m  0.09 s, t. trans:  22.2 min, t. exp. end:  243.0 m  52.7 s\n",
      "9401/111316, progress:  8.45 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  22.5 min, t. exp. end:  243.0 m  43.1 s\n",
      "9501/111316, progress:  8.54 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  22.7 min, t. exp. end:  243.0 m  24.0 s\n",
      "9601/111316, progress:  8.62 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  22.9 min, t. exp. end:  242.0 m  58.6 s\n",
      "9701/111316, progress:  8.71 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  23.2 min, t. exp. end:  242.0 m  51.9 s\n",
      "9801/111316, progress:  8.80 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  23.4 min, t. exp. end:  242.0 m  29.2 s\n",
      "9901/111316, progress:  8.89 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  23.7 min, t. exp. end:  242.0 m  23.0 s\n",
      "10001/111316, progress:  8.98 %, dt:  0.12, exp. dt:  0.14 p/m  0.09 s, t. trans:  23.9 min, t. exp. end:  241.0 m  58.5 s\n",
      "10101/111316, progress:  9.07 %, dt:  0.12, exp. dt:  0.14 p/m  0.09 s, t. trans:  24.1 min, t. exp. end:  241.0 m  54.3 s\n",
      "10201/111316, progress:  9.16 %, dt:  0.13, exp. dt:  0.14 p/m  0.09 s, t. trans:  24.4 min, t. exp. end:  241.0 m  33.5 s\n",
      "10301/111316, progress:  9.25 %, dt:  0.19, exp. dt:  0.14 p/m  0.09 s, t. trans:  24.6 min, t. exp. end:  240.0 m  51.4 s\n",
      "10401/111316, progress:  9.34 %, dt:  0.10, exp. dt:  0.14 p/m  0.09 s, t. trans:  24.8 min, t. exp. end:  240.0 m  35.8 s\n",
      "10501/111316, progress:  9.43 %, dt:  0.11, exp. dt:  0.14 p/m  0.09 s, t. trans:  25.0 min, t. exp. end:  240.0 m  3.8 s\n",
      "10601/111316, progress:  9.52 %, dt:  0.15, exp. dt:  0.14 p/m  0.09 s, t. trans:  25.2 min, t. exp. end:  239.0 m  51.0 s\n",
      "10701/111316, progress:  9.61 %, dt:  0.25, exp. dt:  0.14 p/m  0.09 s, t. trans:  25.5 min, t. exp. end:  239.0 m  27.7 s\n",
      "10801/111316, progress:  9.70 %, dt:  0.14, exp. dt:  0.14 p/m  0.09 s, t. trans:  25.7 min, t. exp. end:  239.0 m  7.2 s\n",
      "10901/111316, progress:  9.79 %, dt:  0.10, exp. dt:  0.14 p/m  0.09 s, t. trans:  25.9 min, t. exp. end:  238.0 m  41.7 s\n",
      "11001/111316, progress:  9.88 %, dt:  0.10, exp. dt:  0.14 p/m  0.09 s, t. trans:  26.1 min, t. exp. end:  238.0 m  2.7 s\n",
      "11101/111316, progress:  9.97 %, dt:  0.11, exp. dt:  0.14 p/m  0.09 s, t. trans:  26.3 min, t. exp. end:  237.0 m  26.2 s\n",
      "11201/111316, progress:  10.06 %, dt:  0.16, exp. dt:  0.14 p/m  0.09 s, t. trans:  26.5 min, t. exp. end:  236.0 m  48.0 s\n",
      "11301/111316, progress:  10.15 %, dt:  0.15, exp. dt:  0.14 p/m  0.09 s, t. trans:  26.7 min, t. exp. end:  236.0 m  28.5 s\n",
      "11401/111316, progress:  10.24 %, dt:  0.10, exp. dt:  0.14 p/m  0.08 s, t. trans:  26.9 min, t. exp. end:  236.0 m  8.5 s\n",
      "11501/111316, progress:  10.33 %, dt:  0.13, exp. dt:  0.14 p/m  0.08 s, t. trans:  27.2 min, t. exp. end:  235.0 m  40.1 s\n",
      "11601/111316, progress:  10.42 %, dt:  0.13, exp. dt:  0.14 p/m  0.08 s, t. trans:  27.4 min, t. exp. end:  235.0 m  26.9 s\n",
      "11701/111316, progress:  10.51 %, dt:  0.11, exp. dt:  0.14 p/m  0.08 s, t. trans:  27.6 min, t. exp. end:  234.0 m  49.7 s\n",
      "11801/111316, progress:  10.60 %, dt:  0.20, exp. dt:  0.14 p/m  0.08 s, t. trans:  27.8 min, t. exp. end:  234.0 m  34.6 s\n",
      "11901/111316, progress:  10.69 %, dt:  0.15, exp. dt:  0.14 p/m  0.08 s, t. trans:  28.0 min, t. exp. end:  234.0 m  18.0 s\n",
      "12001/111316, progress:  10.78 %, dt:  0.15, exp. dt:  0.14 p/m  0.08 s, t. trans:  28.3 min, t. exp. end:  234.0 m  6.0 s\n",
      "12101/111316, progress:  10.87 %, dt:  0.15, exp. dt:  0.14 p/m  0.08 s, t. trans:  28.5 min, t. exp. end:  233.0 m  40.5 s\n",
      "12201/111316, progress:  10.96 %, dt:  0.14, exp. dt:  0.14 p/m  0.08 s, t. trans:  28.7 min, t. exp. end:  233.0 m  30.1 s\n",
      "12301/111316, progress:  11.05 %, dt:  0.13, exp. dt:  0.14 p/m  0.08 s, t. trans:  28.9 min, t. exp. end:  232.0 m  54.0 s\n",
      "12401/111316, progress:  11.14 %, dt:  0.12, exp. dt:  0.14 p/m  0.08 s, t. trans:  29.1 min, t. exp. end:  232.0 m  27.1 s\n",
      "12501/111316, progress:  11.23 %, dt:  0.15, exp. dt:  0.14 p/m  0.08 s, t. trans:  29.4 min, t. exp. end:  232.0 m  8.6 s\n",
      "12601/111316, progress:  11.32 %, dt:  0.11, exp. dt:  0.14 p/m  0.08 s, t. trans:  29.6 min, t. exp. end:  231.0 m  54.9 s\n",
      "12701/111316, progress:  11.41 %, dt:  0.27, exp. dt:  0.14 p/m  0.08 s, t. trans:  29.9 min, t. exp. end:  231.0 m  49.0 s\n",
      "12801/111316, progress:  11.50 %, dt:  0.17, exp. dt:  0.14 p/m  0.08 s, t. trans:  30.1 min, t. exp. end:  231.0 m  38.3 s\n",
      "12901/111316, progress:  11.59 %, dt:  0.12, exp. dt:  0.14 p/m  0.08 s, t. trans:  30.3 min, t. exp. end:  231.0 m  26.5 s\n",
      "13001/111316, progress:  11.68 %, dt:  0.09, exp. dt:  0.14 p/m  0.08 s, t. trans:  30.5 min, t. exp. end:  230.0 m  57.1 s\n",
      "13101/111316, progress:  11.77 %, dt:  0.08, exp. dt:  0.14 p/m  0.08 s, t. trans:  30.7 min, t. exp. end:  230.0 m  19.7 s\n",
      "13201/111316, progress:  11.86 %, dt:  0.13, exp. dt:  0.14 p/m  0.08 s, t. trans:  30.9 min, t. exp. end:  229.0 m  37.0 s\n",
      "13301/111316, progress:  11.95 %, dt:  0.10, exp. dt:  0.14 p/m  0.08 s, t. trans:  31.1 min, t. exp. end:  228.0 m  55.9 s\n",
      "13401/111316, progress:  12.04 %, dt:  0.10, exp. dt:  0.14 p/m  0.08 s, t. trans:  31.2 min, t. exp. end:  228.0 m  15.7 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13501/111316, progress:  12.13 %, dt:  0.10, exp. dt:  0.14 p/m  0.08 s, t. trans:  31.4 min, t. exp. end:  227.0 m  32.3 s\n",
      "13601/111316, progress:  12.22 %, dt:  0.06, exp. dt:  0.14 p/m  0.08 s, t. trans:  31.6 min, t. exp. end:  226.0 m  49.3 s\n",
      "13701/111316, progress:  12.31 %, dt:  0.11, exp. dt:  0.14 p/m  0.08 s, t. trans:  31.7 min, t. exp. end:  226.0 m  7.0 s\n",
      "13801/111316, progress:  12.40 %, dt:  0.09, exp. dt:  0.14 p/m  0.08 s, t. trans:  31.9 min, t. exp. end:  225.0 m  28.2 s\n",
      "13901/111316, progress:  12.49 %, dt:  0.11, exp. dt:  0.14 p/m  0.08 s, t. trans:  32.1 min, t. exp. end:  224.0 m  58.9 s\n",
      "14001/111316, progress:  12.58 %, dt:  0.13, exp. dt:  0.14 p/m  0.08 s, t. trans:  32.3 min, t. exp. end:  224.0 m  36.0 s\n",
      "14101/111316, progress:  12.67 %, dt:  0.15, exp. dt:  0.14 p/m  0.08 s, t. trans:  32.5 min, t. exp. end:  224.0 m  17.3 s\n",
      "14201/111316, progress:  12.76 %, dt:  0.26, exp. dt:  0.14 p/m  0.08 s, t. trans:  32.8 min, t. exp. end:  224.0 m  4.3 s\n",
      "14301/111316, progress:  12.85 %, dt:  0.11, exp. dt:  0.14 p/m  0.08 s, t. trans:  33.0 min, t. exp. end:  223.0 m  38.8 s\n",
      "14401/111316, progress:  12.94 %, dt:  0.13, exp. dt:  0.14 p/m  0.08 s, t. trans:  33.2 min, t. exp. end:  223.0 m  13.4 s\n",
      "14501/111316, progress:  13.03 %, dt:  0.10, exp. dt:  0.14 p/m  0.08 s, t. trans:  33.4 min, t. exp. end:  222.0 m  48.1 s\n",
      "14601/111316, progress:  13.12 %, dt:  0.12, exp. dt:  0.14 p/m  0.08 s, t. trans:  33.6 min, t. exp. end:  222.0 m  26.4 s\n",
      "14701/111316, progress:  13.21 %, dt:  0.13, exp. dt:  0.14 p/m  0.08 s, t. trans:  33.8 min, t. exp. end:  222.0 m  2.5 s\n",
      "14801/111316, progress:  13.30 %, dt:  0.12, exp. dt:  0.14 p/m  0.08 s, t. trans:  34.0 min, t. exp. end:  221.0 m  37.9 s\n",
      "14901/111316, progress:  13.39 %, dt:  0.15, exp. dt:  0.14 p/m  0.08 s, t. trans:  34.2 min, t. exp. end:  221.0 m  16.5 s\n",
      "15001/111316, progress:  13.48 %, dt:  0.10, exp. dt:  0.14 p/m  0.08 s, t. trans:  34.4 min, t. exp. end:  220.0 m  52.2 s\n",
      "15101/111316, progress:  13.57 %, dt:  0.12, exp. dt:  0.14 p/m  0.08 s, t. trans:  34.6 min, t. exp. end:  220.0 m  29.2 s\n",
      "15201/111316, progress:  13.66 %, dt:  0.15, exp. dt:  0.14 p/m  0.08 s, t. trans:  34.8 min, t. exp. end:  220.0 m  5.0 s\n",
      "15301/111316, progress:  13.75 %, dt:  0.11, exp. dt:  0.14 p/m  0.08 s, t. trans:  35.0 min, t. exp. end:  219.0 m  41.1 s\n",
      "15401/111316, progress:  13.84 %, dt:  0.13, exp. dt:  0.14 p/m  0.08 s, t. trans:  35.2 min, t. exp. end:  219.0 m  17.8 s\n",
      "15501/111316, progress:  13.93 %, dt:  0.11, exp. dt:  0.14 p/m  0.08 s, t. trans:  35.4 min, t. exp. end:  218.0 m  55.7 s\n",
      "15601/111316, progress:  14.02 %, dt:  0.10, exp. dt:  0.14 p/m  0.07 s, t. trans:  35.6 min, t. exp. end:  218.0 m  27.7 s\n",
      "15701/111316, progress:  14.10 %, dt:  0.20, exp. dt:  0.14 p/m  0.07 s, t. trans:  35.8 min, t. exp. end:  218.0 m  3.9 s\n",
      "15801/111316, progress:  14.19 %, dt:  0.10, exp. dt:  0.14 p/m  0.07 s, t. trans:  36.0 min, t. exp. end:  217.0 m  39.5 s\n",
      "15901/111316, progress:  14.28 %, dt:  0.15, exp. dt:  0.14 p/m  0.07 s, t. trans:  36.2 min, t. exp. end:  217.0 m  13.9 s\n",
      "16001/111316, progress:  14.37 %, dt:  0.10, exp. dt:  0.14 p/m  0.07 s, t. trans:  36.4 min, t. exp. end:  216.0 m  53.7 s\n",
      "16101/111316, progress:  14.46 %, dt:  0.14, exp. dt:  0.14 p/m  0.07 s, t. trans:  36.6 min, t. exp. end:  216.0 m  32.7 s\n",
      "16201/111316, progress:  14.55 %, dt:  0.12, exp. dt:  0.14 p/m  0.07 s, t. trans:  36.8 min, t. exp. end:  216.0 m  11.9 s\n",
      "16301/111316, progress:  14.64 %, dt:  0.13, exp. dt:  0.14 p/m  0.07 s, t. trans:  37.0 min, t. exp. end:  215.0 m  51.8 s\n",
      "16401/111316, progress:  14.73 %, dt:  0.12, exp. dt:  0.14 p/m  0.07 s, t. trans:  37.2 min, t. exp. end:  215.0 m  30.7 s\n",
      "16501/111316, progress:  14.82 %, dt:  0.11, exp. dt:  0.14 p/m  0.07 s, t. trans:  37.4 min, t. exp. end:  215.0 m  9.5 s\n",
      "16601/111316, progress:  14.91 %, dt:  0.10, exp. dt:  0.14 p/m  0.07 s, t. trans:  37.7 min, t. exp. end:  214.0 m  48.7 s\n",
      "16701/111316, progress:  15.00 %, dt:  0.11, exp. dt:  0.14 p/m  0.17 s, t. trans:  38.2 min, t. exp. end:  216.0 m  21.0 s\n",
      "16801/111316, progress:  15.09 %, dt:  0.14, exp. dt:  0.14 p/m  0.17 s, t. trans:  38.4 min, t. exp. end:  216.0 m  0.1 s\n",
      "16901/111316, progress:  15.18 %, dt:  0.12, exp. dt:  0.14 p/m  0.17 s, t. trans:  38.6 min, t. exp. end:  215.0 m  50.2 s\n",
      "17001/111316, progress:  15.27 %, dt:  0.10, exp. dt:  0.14 p/m  0.17 s, t. trans:  38.9 min, t. exp. end:  215.0 m  32.7 s\n",
      "17101/111316, progress:  15.36 %, dt:  0.21, exp. dt:  0.14 p/m  0.17 s, t. trans:  39.1 min, t. exp. end:  215.0 m  10.1 s\n",
      "17201/111316, progress:  15.45 %, dt:  0.11, exp. dt:  0.14 p/m  0.17 s, t. trans:  39.3 min, t. exp. end:  214.0 m  47.6 s\n",
      "17301/111316, progress:  15.54 %, dt:  0.13, exp. dt:  0.14 p/m  0.17 s, t. trans:  39.5 min, t. exp. end:  214.0 m  27.4 s\n",
      "17401/111316, progress:  15.63 %, dt:  0.14, exp. dt:  0.14 p/m  0.17 s, t. trans:  39.7 min, t. exp. end:  214.0 m  6.6 s\n",
      "17501/111316, progress:  15.72 %, dt:  0.12, exp. dt:  0.14 p/m  0.17 s, t. trans:  39.9 min, t. exp. end:  213.0 m  44.5 s\n",
      "17601/111316, progress:  15.81 %, dt:  0.12, exp. dt:  0.14 p/m  0.17 s, t. trans:  40.1 min, t. exp. end:  213.0 m  23.6 s\n",
      "17701/111316, progress:  15.90 %, dt:  0.12, exp. dt:  0.14 p/m  0.17 s, t. trans:  40.3 min, t. exp. end:  213.0 m  3.8 s\n",
      "17801/111316, progress:  15.99 %, dt:  0.12, exp. dt:  0.14 p/m  0.17 s, t. trans:  40.5 min, t. exp. end:  212.0 m  40.5 s\n",
      "17901/111316, progress:  16.08 %, dt:  0.14, exp. dt:  0.14 p/m  0.17 s, t. trans:  40.7 min, t. exp. end:  212.0 m  19.2 s\n",
      "18001/111316, progress:  16.17 %, dt:  0.12, exp. dt:  0.14 p/m  0.17 s, t. trans:  40.9 min, t. exp. end:  212.0 m  2.7 s\n",
      "18101/111316, progress:  16.26 %, dt:  0.11, exp. dt:  0.14 p/m  0.16 s, t. trans:  41.1 min, t. exp. end:  211.0 m  45.7 s\n",
      "18201/111316, progress:  16.35 %, dt:  0.10, exp. dt:  0.14 p/m  0.16 s, t. trans:  41.3 min, t. exp. end:  211.0 m  15.7 s\n",
      "18301/111316, progress:  16.44 %, dt:  0.10, exp. dt:  0.14 p/m  0.16 s, t. trans:  41.5 min, t. exp. end:  210.0 m  42.6 s\n",
      "18401/111316, progress:  16.53 %, dt:  0.12, exp. dt:  0.14 p/m  0.16 s, t. trans:  41.6 min, t. exp. end:  210.0 m  13.3 s\n",
      "18501/111316, progress:  16.62 %, dt:  0.10, exp. dt:  0.14 p/m  0.16 s, t. trans:  41.8 min, t. exp. end:  209.0 m  49.0 s\n",
      "18601/111316, progress:  16.71 %, dt:  0.12, exp. dt:  0.14 p/m  0.16 s, t. trans:  42.0 min, t. exp. end:  209.0 m  15.4 s\n",
      "18701/111316, progress:  16.80 %, dt:  0.09, exp. dt:  0.14 p/m  0.16 s, t. trans:  42.1 min, t. exp. end:  208.0 m  44.4 s\n",
      "18801/111316, progress:  16.89 %, dt:  0.10, exp. dt:  0.14 p/m  0.16 s, t. trans:  42.3 min, t. exp. end:  208.0 m  11.4 s\n",
      "18901/111316, progress:  16.98 %, dt:  0.15, exp. dt:  0.13 p/m  0.16 s, t. trans:  42.5 min, t. exp. end:  207.0 m  42.8 s\n",
      "19001/111316, progress:  17.07 %, dt:  0.09, exp. dt:  0.13 p/m  0.16 s, t. trans:  42.6 min, t. exp. end:  207.0 m  12.2 s\n",
      "19101/111316, progress:  17.16 %, dt:  0.09, exp. dt:  0.13 p/m  0.16 s, t. trans:  42.8 min, t. exp. end:  206.0 m  40.7 s\n",
      "19201/111316, progress:  17.25 %, dt:  0.17, exp. dt:  0.13 p/m  0.16 s, t. trans:  43.0 min, t. exp. end:  206.0 m  15.7 s\n",
      "19301/111316, progress:  17.34 %, dt:  0.08, exp. dt:  0.13 p/m  0.16 s, t. trans:  43.2 min, t. exp. end:  205.0 m  44.3 s\n",
      "19401/111316, progress:  17.43 %, dt:  0.11, exp. dt:  0.13 p/m  0.16 s, t. trans:  43.3 min, t. exp. end:  205.0 m  21.0 s\n",
      "19501/111316, progress:  17.52 %, dt:  0.23, exp. dt:  0.13 p/m  0.16 s, t. trans:  43.5 min, t. exp. end:  204.0 m  54.9 s\n",
      "19601/111316, progress:  17.61 %, dt:  0.11, exp. dt:  0.13 p/m  0.16 s, t. trans:  43.7 min, t. exp. end:  204.0 m  25.9 s\n",
      "19701/111316, progress:  17.70 %, dt:  0.10, exp. dt:  0.13 p/m  0.16 s, t. trans:  43.9 min, t. exp. end:  203.0 m  58.7 s\n",
      "19801/111316, progress:  17.79 %, dt:  0.11, exp. dt:  0.13 p/m  0.16 s, t. trans:  44.0 min, t. exp. end:  203.0 m  30.4 s\n",
      "19901/111316, progress:  17.88 %, dt:  0.10, exp. dt:  0.13 p/m  0.16 s, t. trans:  44.2 min, t. exp. end:  203.0 m  4.5 s\n",
      "20001/111316, progress:  17.97 %, dt:  0.10, exp. dt:  0.13 p/m  0.16 s, t. trans:  44.4 min, t. exp. end:  202.0 m  34.4 s\n",
      "20101/111316, progress:  18.06 %, dt:  0.10, exp. dt:  0.13 p/m  0.16 s, t. trans:  44.5 min, t. exp. end:  202.0 m  3.8 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201/111316, progress:  18.15 %, dt:  0.10, exp. dt:  0.13 p/m  0.16 s, t. trans:  44.7 min, t. exp. end:  201.0 m  36.7 s\n",
      "20301/111316, progress:  18.24 %, dt:  0.09, exp. dt:  0.13 p/m  0.16 s, t. trans:  44.9 min, t. exp. end:  201.0 m  8.1 s\n",
      "20401/111316, progress:  18.33 %, dt:  0.09, exp. dt:  0.13 p/m  0.16 s, t. trans:  45.0 min, t. exp. end:  200.0 m  40.2 s\n",
      "20501/111316, progress:  18.42 %, dt:  0.09, exp. dt:  0.13 p/m  0.16 s, t. trans:  45.2 min, t. exp. end:  200.0 m  13.4 s\n",
      "20601/111316, progress:  18.51 %, dt:  0.09, exp. dt:  0.13 p/m  0.16 s, t. trans:  45.4 min, t. exp. end:  199.0 m  42.5 s\n",
      "20701/111316, progress:  18.60 %, dt:  0.09, exp. dt:  0.13 p/m  0.15 s, t. trans:  45.5 min, t. exp. end:  199.0 m  13.6 s\n",
      "20801/111316, progress:  18.69 %, dt:  0.10, exp. dt:  0.13 p/m  0.15 s, t. trans:  45.7 min, t. exp. end:  198.0 m  47.2 s\n",
      "20901/111316, progress:  18.78 %, dt:  0.09, exp. dt:  0.13 p/m  0.15 s, t. trans:  45.9 min, t. exp. end:  198.0 m  23.4 s\n",
      "21001/111316, progress:  18.87 %, dt:  0.09, exp. dt:  0.13 p/m  0.15 s, t. trans:  46.0 min, t. exp. end:  197.0 m  58.0 s\n",
      "21101/111316, progress:  18.96 %, dt:  0.10, exp. dt:  0.13 p/m  0.15 s, t. trans:  46.2 min, t. exp. end:  197.0 m  28.8 s\n",
      "21201/111316, progress:  19.05 %, dt:  0.08, exp. dt:  0.13 p/m  0.15 s, t. trans:  46.4 min, t. exp. end:  197.0 m  2.6 s\n",
      "21301/111316, progress:  19.14 %, dt:  0.12, exp. dt:  0.13 p/m  0.15 s, t. trans:  46.5 min, t. exp. end:  196.0 m  36.4 s\n",
      "21401/111316, progress:  19.23 %, dt:  0.09, exp. dt:  0.13 p/m  0.15 s, t. trans:  46.7 min, t. exp. end:  196.0 m  12.4 s\n",
      "21501/111316, progress:  19.32 %, dt:  0.08, exp. dt:  0.13 p/m  0.15 s, t. trans:  46.9 min, t. exp. end:  195.0 m  48.9 s\n",
      "21601/111316, progress:  19.41 %, dt:  0.14, exp. dt:  0.13 p/m  0.15 s, t. trans:  47.1 min, t. exp. end:  195.0 m  30.3 s\n",
      "21701/111316, progress:  19.49 %, dt:  0.13, exp. dt:  0.13 p/m  0.15 s, t. trans:  47.3 min, t. exp. end:  195.0 m  8.4 s\n",
      "21801/111316, progress:  19.58 %, dt:  0.09, exp. dt:  0.13 p/m  0.15 s, t. trans:  47.4 min, t. exp. end:  194.0 m  45.2 s\n",
      "21901/111316, progress:  19.67 %, dt:  0.12, exp. dt:  0.13 p/m  0.15 s, t. trans:  47.6 min, t. exp. end:  194.0 m  27.7 s\n",
      "22001/111316, progress:  19.76 %, dt:  0.17, exp. dt:  0.13 p/m  0.15 s, t. trans:  47.9 min, t. exp. end:  194.0 m  15.9 s\n",
      "22101/111316, progress:  19.85 %, dt:  0.11, exp. dt:  0.13 p/m  0.15 s, t. trans:  48.1 min, t. exp. end:  193.0 m  59.5 s\n",
      "22201/111316, progress:  19.94 %, dt:  0.19, exp. dt:  0.13 p/m  0.15 s, t. trans:  48.3 min, t. exp. end:  193.0 m  47.4 s\n",
      "22301/111316, progress:  20.03 %, dt:  0.10, exp. dt:  0.13 p/m  0.15 s, t. trans:  48.5 min, t. exp. end:  193.0 m  26.3 s\n",
      "22401/111316, progress:  20.12 %, dt:  0.11, exp. dt:  0.13 p/m  0.15 s, t. trans:  48.7 min, t. exp. end:  193.0 m  9.0 s\n",
      "22501/111316, progress:  20.21 %, dt:  0.13, exp. dt:  0.13 p/m  0.15 s, t. trans:  48.9 min, t. exp. end:  192.0 m  58.0 s\n",
      "22601/111316, progress:  20.30 %, dt:  0.12, exp. dt:  0.13 p/m  0.15 s, t. trans:  49.1 min, t. exp. end:  192.0 m  38.2 s\n",
      "22701/111316, progress:  20.39 %, dt:  0.12, exp. dt:  0.13 p/m  0.15 s, t. trans:  49.3 min, t. exp. end:  192.0 m  15.2 s\n",
      "22801/111316, progress:  20.48 %, dt:  0.12, exp. dt:  0.13 p/m  0.15 s, t. trans:  49.4 min, t. exp. end:  191.0 m  52.0 s\n",
      "22901/111316, progress:  20.57 %, dt:  0.09, exp. dt:  0.13 p/m  0.15 s, t. trans:  49.6 min, t. exp. end:  191.0 m  27.4 s\n",
      "23001/111316, progress:  20.66 %, dt:  0.11, exp. dt:  0.13 p/m  0.15 s, t. trans:  49.7 min, t. exp. end:  191.0 m  1.2 s\n",
      "23101/111316, progress:  20.75 %, dt:  0.10, exp. dt:  0.13 p/m  0.15 s, t. trans:  49.9 min, t. exp. end:  190.0 m  36.0 s\n",
      "23201/111316, progress:  20.84 %, dt:  0.09, exp. dt:  0.13 p/m  0.15 s, t. trans:  50.1 min, t. exp. end:  190.0 m  12.4 s\n",
      "23301/111316, progress:  20.93 %, dt:  0.10, exp. dt:  0.13 p/m  0.15 s, t. trans:  50.2 min, t. exp. end:  189.0 m  48.1 s\n",
      "23401/111316, progress:  21.02 %, dt:  0.10, exp. dt:  0.13 p/m  0.15 s, t. trans:  50.4 min, t. exp. end:  189.0 m  24.9 s\n",
      "23501/111316, progress:  21.11 %, dt:  0.07, exp. dt:  0.13 p/m  0.15 s, t. trans:  50.6 min, t. exp. end:  189.0 m  1.2 s\n",
      "23601/111316, progress:  21.20 %, dt:  0.08, exp. dt:  0.13 p/m  0.15 s, t. trans:  50.8 min, t. exp. end:  188.0 m  37.6 s\n",
      "23701/111316, progress:  21.29 %, dt:  0.09, exp. dt:  0.13 p/m  0.15 s, t. trans:  50.9 min, t. exp. end:  188.0 m  12.1 s\n",
      "23801/111316, progress:  21.38 %, dt:  0.12, exp. dt:  0.13 p/m  0.15 s, t. trans:  51.1 min, t. exp. end:  187.0 m  52.1 s\n",
      "23901/111316, progress:  21.47 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  51.3 min, t. exp. end:  187.0 m  30.0 s\n",
      "24001/111316, progress:  21.56 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  51.4 min, t. exp. end:  187.0 m  8.3 s\n",
      "24101/111316, progress:  21.65 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  51.6 min, t. exp. end:  186.0 m  49.4 s\n",
      "24201/111316, progress:  21.74 %, dt:  0.13, exp. dt:  0.13 p/m  0.14 s, t. trans:  51.8 min, t. exp. end:  186.0 m  26.5 s\n",
      "24301/111316, progress:  21.83 %, dt:  0.20, exp. dt:  0.13 p/m  0.14 s, t. trans:  52.0 min, t. exp. end:  186.0 m  4.4 s\n",
      "24401/111316, progress:  21.92 %, dt:  0.07, exp. dt:  0.13 p/m  0.14 s, t. trans:  52.1 min, t. exp. end:  185.0 m  39.9 s\n",
      "24501/111316, progress:  22.01 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  52.3 min, t. exp. end:  185.0 m  16.8 s\n",
      "24601/111316, progress:  22.10 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  52.5 min, t. exp. end:  184.0 m  53.7 s\n",
      "24701/111316, progress:  22.19 %, dt:  0.16, exp. dt:  0.13 p/m  0.14 s, t. trans:  52.6 min, t. exp. end:  184.0 m  32.2 s\n",
      "24801/111316, progress:  22.28 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  52.8 min, t. exp. end:  184.0 m  18.0 s\n",
      "24901/111316, progress:  22.37 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  53.0 min, t. exp. end:  183.0 m  54.9 s\n",
      "25001/111316, progress:  22.46 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  53.2 min, t. exp. end:  183.0 m  33.8 s\n",
      "25101/111316, progress:  22.55 %, dt:  0.13, exp. dt:  0.13 p/m  0.14 s, t. trans:  53.3 min, t. exp. end:  183.0 m  13.7 s\n",
      "25201/111316, progress:  22.64 %, dt:  0.21, exp. dt:  0.13 p/m  0.14 s, t. trans:  53.5 min, t. exp. end:  182.0 m  52.7 s\n",
      "25301/111316, progress:  22.73 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  53.7 min, t. exp. end:  182.0 m  29.9 s\n",
      "25401/111316, progress:  22.82 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  53.9 min, t. exp. end:  182.0 m  8.4 s\n",
      "25501/111316, progress:  22.91 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  54.0 min, t. exp. end:  181.0 m  46.7 s\n",
      "25601/111316, progress:  23.00 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  54.2 min, t. exp. end:  181.0 m  27.4 s\n",
      "25701/111316, progress:  23.09 %, dt:  0.33, exp. dt:  0.13 p/m  0.14 s, t. trans:  54.5 min, t. exp. end:  181.0 m  34.7 s\n",
      "25801/111316, progress:  23.18 %, dt:  0.12, exp. dt:  0.13 p/m  0.14 s, t. trans:  54.8 min, t. exp. end:  181.0 m  40.4 s\n",
      "25901/111316, progress:  23.27 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  55.0 min, t. exp. end:  181.0 m  19.8 s\n",
      "26001/111316, progress:  23.36 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  55.2 min, t. exp. end:  180.0 m  57.9 s\n",
      "26101/111316, progress:  23.45 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  55.3 min, t. exp. end:  180.0 m  41.4 s\n",
      "26201/111316, progress:  23.54 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  55.5 min, t. exp. end:  180.0 m  21.6 s\n",
      "26301/111316, progress:  23.63 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  55.7 min, t. exp. end:  180.0 m  0.6 s\n",
      "26401/111316, progress:  23.72 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  55.9 min, t. exp. end:  179.0 m  50.9 s\n",
      "26501/111316, progress:  23.81 %, dt:  0.21, exp. dt:  0.13 p/m  0.14 s, t. trans:  56.2 min, t. exp. end:  179.0 m  53.0 s\n",
      "26601/111316, progress:  23.90 %, dt:  0.21, exp. dt:  0.13 p/m  0.14 s, t. trans:  56.6 min, t. exp. end:  180.0 m  21.5 s\n",
      "26701/111316, progress:  23.99 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  56.8 min, t. exp. end:  180.0 m  0.3 s\n",
      "26801/111316, progress:  24.08 %, dt:  0.24, exp. dt:  0.13 p/m  0.14 s, t. trans:  57.1 min, t. exp. end:  179.0 m  55.7 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26901/111316, progress:  24.17 %, dt:  0.27, exp. dt:  0.13 p/m  0.14 s, t. trans:  57.5 min, t. exp. end:  180.0 m  18.7 s\n",
      "27001/111316, progress:  24.26 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  57.6 min, t. exp. end:  179.0 m  57.8 s\n",
      "27101/111316, progress:  24.35 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  57.8 min, t. exp. end:  179.0 m  35.6 s\n",
      "27201/111316, progress:  24.44 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  58.0 min, t. exp. end:  179.0 m  15.9 s\n",
      "27301/111316, progress:  24.53 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  58.1 min, t. exp. end:  178.0 m  56.7 s\n",
      "27401/111316, progress:  24.62 %, dt:  0.19, exp. dt:  0.13 p/m  0.14 s, t. trans:  58.3 min, t. exp. end:  178.0 m  34.8 s\n",
      "27501/111316, progress:  24.71 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  58.5 min, t. exp. end:  178.0 m  12.4 s\n",
      "27601/111316, progress:  24.80 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  58.6 min, t. exp. end:  177.0 m  51.3 s\n",
      "27701/111316, progress:  24.89 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  58.8 min, t. exp. end:  177.0 m  31.6 s\n",
      "27801/111316, progress:  24.97 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  59.0 min, t. exp. end:  177.0 m  10.3 s\n",
      "27901/111316, progress:  25.06 %, dt:  0.12, exp. dt:  0.13 p/m  0.14 s, t. trans:  59.1 min, t. exp. end:  176.0 m  49.0 s\n",
      "28001/111316, progress:  25.15 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  59.3 min, t. exp. end:  176.0 m  29.4 s\n",
      "28101/111316, progress:  25.24 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  59.5 min, t. exp. end:  176.0 m  9.4 s\n",
      "28201/111316, progress:  25.33 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  59.7 min, t. exp. end:  175.0 m  49.7 s\n",
      "28301/111316, progress:  25.42 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  59.8 min, t. exp. end:  175.0 m  29.7 s\n",
      "28401/111316, progress:  25.51 %, dt:  0.17, exp. dt:  0.13 p/m  0.14 s, t. trans:  60.1 min, t. exp. end:  175.0 m  19.2 s\n",
      "28501/111316, progress:  25.60 %, dt:  0.09, exp. dt:  0.13 p/m  0.13 s, t. trans:  60.2 min, t. exp. end:  175.0 m  2.6 s\n",
      "28601/111316, progress:  25.69 %, dt:  0.10, exp. dt:  0.13 p/m  0.13 s, t. trans:  60.4 min, t. exp. end:  174.0 m  47.1 s\n",
      "28701/111316, progress:  25.78 %, dt:  0.10, exp. dt:  0.13 p/m  0.13 s, t. trans:  60.6 min, t. exp. end:  174.0 m  28.8 s\n",
      "28801/111316, progress:  25.87 %, dt:  0.09, exp. dt:  0.13 p/m  0.13 s, t. trans:  60.8 min, t. exp. end:  174.0 m  9.2 s\n",
      "28901/111316, progress:  25.96 %, dt:  0.10, exp. dt:  0.13 p/m  0.13 s, t. trans:  61.0 min, t. exp. end:  173.0 m  48.5 s\n",
      "29001/111316, progress:  26.05 %, dt:  0.23, exp. dt:  0.13 p/m  0.13 s, t. trans:  61.2 min, t. exp. end:  173.0 m  45.2 s\n",
      "29101/111316, progress:  26.14 %, dt:  0.11, exp. dt:  0.13 p/m  0.13 s, t. trans:  61.5 min, t. exp. end:  173.0 m  45.6 s\n",
      "29201/111316, progress:  26.23 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  61.8 min, t. exp. end:  173.0 m  50.7 s\n",
      "29301/111316, progress:  26.32 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  62.0 min, t. exp. end:  173.0 m  30.7 s\n",
      "29401/111316, progress:  26.41 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  62.1 min, t. exp. end:  173.0 m  9.5 s\n",
      "29501/111316, progress:  26.50 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  62.3 min, t. exp. end:  172.0 m  48.7 s\n",
      "29601/111316, progress:  26.59 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  62.5 min, t. exp. end:  172.0 m  29.0 s\n",
      "29701/111316, progress:  26.68 %, dt:  0.12, exp. dt:  0.13 p/m  0.14 s, t. trans:  62.7 min, t. exp. end:  172.0 m  13.1 s\n",
      "29801/111316, progress:  26.77 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  62.9 min, t. exp. end:  171.0 m  55.9 s\n",
      "29901/111316, progress:  26.86 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  63.0 min, t. exp. end:  171.0 m  36.3 s\n",
      "30001/111316, progress:  26.95 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  63.2 min, t. exp. end:  171.0 m  17.9 s\n",
      "30101/111316, progress:  27.04 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  63.4 min, t. exp. end:  171.0 m  1.1 s\n",
      "30201/111316, progress:  27.13 %, dt:  0.12, exp. dt:  0.13 p/m  0.14 s, t. trans:  63.6 min, t. exp. end:  170.0 m  42.8 s\n",
      "30301/111316, progress:  27.22 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  63.7 min, t. exp. end:  170.0 m  22.1 s\n",
      "30401/111316, progress:  27.31 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  63.9 min, t. exp. end:  170.0 m  2.4 s\n",
      "30501/111316, progress:  27.40 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  64.1 min, t. exp. end:  169.0 m  42.7 s\n",
      "30601/111316, progress:  27.49 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  64.2 min, t. exp. end:  169.0 m  22.0 s\n",
      "30701/111316, progress:  27.58 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  64.4 min, t. exp. end:  169.0 m  2.0 s\n",
      "30801/111316, progress:  27.67 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  64.5 min, t. exp. end:  168.0 m  40.7 s\n",
      "30901/111316, progress:  27.76 %, dt:  0.11, exp. dt:  0.13 p/m  0.14 s, t. trans:  64.7 min, t. exp. end:  168.0 m  19.0 s\n",
      "31001/111316, progress:  27.85 %, dt:  0.18, exp. dt:  0.13 p/m  0.14 s, t. trans:  64.8 min, t. exp. end:  167.0 m  59.2 s\n",
      "31101/111316, progress:  27.94 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  65.0 min, t. exp. end:  167.0 m  40.7 s\n",
      "31201/111316, progress:  28.03 %, dt:  0.08, exp. dt:  0.13 p/m  0.14 s, t. trans:  65.2 min, t. exp. end:  167.0 m  20.8 s\n",
      "31301/111316, progress:  28.12 %, dt:  0.10, exp. dt:  0.13 p/m  0.14 s, t. trans:  65.3 min, t. exp. end:  167.0 m  2.0 s\n",
      "31401/111316, progress:  28.21 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  65.5 min, t. exp. end:  166.0 m  41.8 s\n",
      "31501/111316, progress:  28.30 %, dt:  0.09, exp. dt:  0.13 p/m  0.14 s, t. trans:  65.7 min, t. exp. end:  166.0 m  23.1 s\n",
      "31601/111316, progress:  28.39 %, dt:  0.21, exp. dt:  0.13 p/m  0.14 s, t. trans:  65.8 min, t. exp. end:  166.0 m  5.2 s\n",
      "31701/111316, progress:  28.48 %, dt:  0.13, exp. dt:  0.12 p/m  0.14 s, t. trans:  66.0 min, t. exp. end:  165.0 m  45.7 s\n",
      "31801/111316, progress:  28.57 %, dt:  0.10, exp. dt:  0.12 p/m  0.14 s, t. trans:  66.2 min, t. exp. end:  165.0 m  28.0 s\n",
      "31901/111316, progress:  28.66 %, dt:  0.17, exp. dt:  0.12 p/m  0.14 s, t. trans:  66.3 min, t. exp. end:  165.0 m  9.4 s\n",
      "32001/111316, progress:  28.75 %, dt:  0.09, exp. dt:  0.12 p/m  0.14 s, t. trans:  66.5 min, t. exp. end:  164.0 m  51.1 s\n",
      "32101/111316, progress:  28.84 %, dt:  0.10, exp. dt:  0.12 p/m  0.14 s, t. trans:  66.7 min, t. exp. end:  164.0 m  32.4 s\n",
      "32201/111316, progress:  28.93 %, dt:  0.11, exp. dt:  0.12 p/m  0.14 s, t. trans:  66.9 min, t. exp. end:  164.0 m  16.3 s\n",
      "32301/111316, progress:  29.02 %, dt:  0.08, exp. dt:  0.12 p/m  0.14 s, t. trans:  67.0 min, t. exp. end:  163.0 m  56.2 s\n",
      "32401/111316, progress:  29.11 %, dt:  0.08, exp. dt:  0.12 p/m  0.14 s, t. trans:  67.2 min, t. exp. end:  163.0 m  37.0 s\n",
      "32501/111316, progress:  29.20 %, dt:  0.10, exp. dt:  0.12 p/m  0.13 s, t. trans:  67.3 min, t. exp. end:  163.0 m  18.8 s\n",
      "32601/111316, progress:  29.29 %, dt:  0.18, exp. dt:  0.12 p/m  0.13 s, t. trans:  67.5 min, t. exp. end:  163.0 m  0.9 s\n",
      "32701/111316, progress:  29.38 %, dt:  0.10, exp. dt:  0.12 p/m  0.13 s, t. trans:  67.7 min, t. exp. end:  162.0 m  44.5 s\n",
      "32801/111316, progress:  29.47 %, dt:  0.09, exp. dt:  0.12 p/m  0.13 s, t. trans:  67.9 min, t. exp. end:  162.0 m  27.1 s\n",
      "32901/111316, progress:  29.56 %, dt:  0.11, exp. dt:  0.12 p/m  0.13 s, t. trans:  68.1 min, t. exp. end:  162.0 m  11.3 s\n",
      "33001/111316, progress:  29.65 %, dt:  0.09, exp. dt:  0.12 p/m  0.13 s, t. trans:  68.2 min, t. exp. end:  161.0 m  54.9 s\n",
      "33101/111316, progress:  29.74 %, dt:  0.10, exp. dt:  0.12 p/m  0.13 s, t. trans:  68.4 min, t. exp. end:  161.0 m  39.2 s\n",
      "33201/111316, progress:  29.83 %, dt:  0.10, exp. dt:  0.12 p/m  0.13 s, t. trans:  68.6 min, t. exp. end:  161.0 m  22.3 s\n",
      "33301/111316, progress:  29.92 %, dt:  0.10, exp. dt:  0.12 p/m  0.13 s, t. trans:  68.8 min, t. exp. end:  161.0 m  6.1 s\n",
      "33401/111316, progress:  30.01 %, dt:  0.11, exp. dt:  0.12 p/m  0.13 s, t. trans:  68.9 min, t. exp. end:  160.0 m  49.4 s\n",
      "33501/111316, progress:  30.10 %, dt:  0.11, exp. dt:  0.12 p/m  0.13 s, t. trans:  69.1 min, t. exp. end:  160.0 m  34.0 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33601/111316, progress:  30.19 %, dt:  0.12, exp. dt:  0.12 p/m  0.13 s, t. trans:  69.3 min, t. exp. end:  160.0 m  18.6 s\n",
      "33701/111316, progress:  30.28 %, dt:  0.08, exp. dt:  0.12 p/m  0.13 s, t. trans:  69.5 min, t. exp. end:  160.0 m  2.9 s\n",
      "33801/111316, progress:  30.36 %, dt:  0.09, exp. dt:  0.12 p/m  0.13 s, t. trans:  69.7 min, t. exp. end:  159.0 m  44.1 s\n",
      "33901/111316, progress:  30.45 %, dt:  0.09, exp. dt:  0.12 p/m  0.13 s, t. trans:  69.8 min, t. exp. end:  159.0 m  25.2 s\n",
      "34001/111316, progress:  30.54 %, dt:  0.10, exp. dt:  0.12 p/m  0.13 s, t. trans:  70.0 min, t. exp. end:  159.0 m  9.0 s\n",
      "34101/111316, progress:  30.63 %, dt:  0.19, exp. dt:  0.12 p/m  0.13 s, t. trans:  70.2 min, t. exp. end:  159.0 m  0.9 s\n",
      "34201/111316, progress:  30.72 %, dt:  0.09, exp. dt:  0.12 p/m  0.13 s, t. trans:  70.5 min, t. exp. end:  158.0 m  56.4 s\n",
      "34301/111316, progress:  30.81 %, dt:  0.08, exp. dt:  0.12 p/m  0.13 s, t. trans:  70.7 min, t. exp. end:  158.0 m  40.1 s\n",
      "34401/111316, progress:  30.90 %, dt:  0.12, exp. dt:  0.12 p/m  0.13 s, t. trans:  70.8 min, t. exp. end:  158.0 m  22.4 s\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-384369c1a17b>\u001b[0m in \u001b[0;36mget_preprocessing\u001b[1;34m(self, D)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0mixq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mixa\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Q_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mixa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mixq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m             \u001b[0mdata_representations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-384369c1a17b>\u001b[0m in \u001b[0;36mget_features\u001b[1;34m(self, ixa, ixq, a, q)\u001b[0m\n\u001b[0;32m    576\u001b[0m                 \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_representation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mixa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mixq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_topo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mixa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m                 \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mixa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[0mdic_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dic_attrib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mixa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-384369c1a17b>\u001b[0m in \u001b[0;36mget_topo\u001b[1;34m(self, ix, a)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_topo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdic_topo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdic_topo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_topo_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdic_topo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-384369c1a17b>\u001b[0m in \u001b[0;36mget_topo_features\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>prop_digit_char\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>len(~A)\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>len(~A)\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>max_vowel_rep_char_per_token\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_type_rep_char_per_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"vowel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m     \u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>prop_no_digit_no_math_punct\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmath_punct\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>len(~A)\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m     \u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>num_alpha\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>prop_alpha_vowels\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m\"aeiou\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>num_alpha\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"traditional<&>num_alpha\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preproc = Preprocessing()\n",
    "df_features = preproc.get_preprocessing(task_C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cols_train = set(df_features_train.columns)\n",
    "cols_val = set(df_features_val.columns)\n",
    "cols_test = set(df_features_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_val = cols_val.difference(cols_train)\n",
    "drop_test = cols_test.difference(cols_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add_val = cols_train.difference(cols_val)\n",
    "add_test = cols_train.difference(cols_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mf_features_train = df_features_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mf_features_val = df_features_val.drop(columns=drop_val)\n",
    "zero_cols = pd.concat([mf_features_val.iloc[:, 0] * 0] * len(add_val), axis=1)\n",
    "zero_cols.columns = add_val\n",
    "mf_features_val = pd.concat([mf_features_val, zero_cols], axis=1)[df_features_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mf_features_test = df_features_test.drop(columns=drop_test)\n",
    "zero_cols = pd.concat([mf_features_test.iloc[:, 0] * 0] * len(add_test), axis=1)\n",
    "zero_cols.columns = add_test\n",
    "mf_features_test = pd.concat([mf_features_test, zero_cols], axis=1)[df_features_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.all(\n",
    "    (mf_features_train.columns == mf_features_val.columns) \n",
    "    & \n",
    "    (mf_features_val.columns== mf_features_test.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0557feeb",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "08163a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# mf_features_train.to_excel(\"../features/mf_features_train_task_C1.xlsx\")\n",
    "# mf_features_val.to_excel(\"../features/mf_features_val_task_C1.xlsx\")\n",
    "# mf_features_test.to_excel(\"../features/mf_features_test_task_C1.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
